{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:12.350811Z",
     "end_time": "2023-05-11T11:05:14.990781Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import importlib.util\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import albumentations as albu\n",
    "import wandb\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import lr_scheduler as LRS\n",
    "\n",
    "import model.cv_metric as module_metric\n",
    "import model.loss as module_loss\n",
    "from logger.Loggers import *\n",
    "from model.model import VesuviusModel as CustomModel\n",
    "from utils import *\n",
    "from utils.env_detect import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configs\n",
    "### Env detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:14.992781Z",
     "end_time": "2023-05-11T11:05:15.007781Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Logger = get_logger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Auto settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:15.007781Z",
     "end_time": "2023-05-11T11:05:15.032200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============== augmentation =============\n",
    "def get_aug_list(size, in_channels, mode='train'):\n",
    "    \"\"\"\n",
    "    type: train, valid\n",
    "    return: list of albumentations\n",
    "\n",
    "    in case of any further modification,\n",
    "    one should use albu.Compose by themselves\n",
    "    \"\"\"\n",
    "\n",
    "    train_aug_list = [\n",
    "        # A.RandomResizedCrop(\n",
    "        #     size, size, scale=(0.85, 1.0)),\n",
    "        albu.Resize(size, size),\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.5),\n",
    "        albu.RandomBrightnessContrast(p=0.75),\n",
    "        albu.ShiftScaleRotate(p=0.75),\n",
    "        albu.OneOf([\n",
    "            albu.GaussNoise(var_limit=(10.0, 50.0)),\n",
    "            albu.GaussianBlur(),\n",
    "            albu.MotionBlur(),\n",
    "        ], p=0.4),\n",
    "        albu.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        albu.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3),\n",
    "                           mask_fill_value=0, p=0.5),\n",
    "        # A.Cutout(max_h_size=int(size * 0.6),\n",
    "        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "\n",
    "        albu.Normalize(\n",
    "            mean=[0] * in_channels,\n",
    "            std=[1] * in_channels,\n",
    "            # max_pixel_value=1.0,\n",
    "            always_apply=True,\n",
    "        ),\n",
    "        # pad is placed last\n",
    "        # for not interfering with other aug,i.e.Normalize\n",
    "        albu.PadIfNeeded(size, size,\n",
    "                         position='top_left'),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "\n",
    "    valid_aug_list = [\n",
    "        albu.Resize(size, size),\n",
    "        albu.Normalize(\n",
    "            mean=[0] * in_channels,\n",
    "            std=[1] * in_channels,\n",
    "            # max_pixel_value=1.0,\n",
    "            always_apply=True,\n",
    "        ),\n",
    "        albu.PadIfNeeded(size, size,\n",
    "                         position='top_left'),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "\n",
    "    if mode == 'train':\n",
    "        return train_aug_list\n",
    "    else:\n",
    "        return valid_aug_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:15.026201Z",
     "end_time": "2023-05-11T11:05:15.047202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:15.038202Z",
     "end_time": "2023-05-11T11:05:15.052202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def get_config():\n",
    "    HOST, PATHS = decide_paths()\n",
    "    _cfg = yaml.safe_load(open(f\"{PATHS['ROOT_DIR']}/dev/default_config.yaml\", \"r\"))\n",
    "\n",
    "    util.seed_everything(_cfg['seed'])\n",
    "\n",
    "    PATHS = {k: str(v) for k, v in PATHS.items()}\n",
    "    _cfg[\"PATHS\"] = PATHS\n",
    "\n",
    "    _cfg['dataset']['data_dir'] = PATHS['DATA_DIR']\n",
    "    _cfg['dataset']['cache_dir'] = PATHS['CACHE_DIR']\n",
    "\n",
    "    with open(\"config.yaml\", \"w\") as f:\n",
    "        yaml.dump(_cfg, f)\n",
    "\n",
    "    # update in running cfgs\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                          else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    _cfg[\"device\"] = device\n",
    "\n",
    "    _cfg[\"kaggle_run_type\"] = os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\")\n",
    "    _cfg['HOST'] = HOST\n",
    "    \n",
    "    _cfg['data_loader']['num_workers'] = max(\n",
    "        _cfg['data_loader']['num_workers'], os.cpu_count()-2)\n",
    "    # model id consist of settings of model,\n",
    "    # exp_id add on the settings for dataset\n",
    "    # run_id add on time\n",
    "    cfg_model = _cfg['model']\n",
    "    _cfg['model_id'] = f\"{cfg_model['Proto']}_{cfg_model['in_channels']}_{cfg_model['model_type']}\"\n",
    "\n",
    "    _cfg['model_id'] += f\"fold_( {'_'.join(_cfg['dataset']['image_sets'])} )\"\n",
    "    _cfg['exp_id'] = f\"{_cfg['model_id']}_{cfg_model['tile_size']}\"\n",
    "    _cfg['run_id'] = f\"{_cfg['exp_id']}_{time.strftime('%m%d_%H%M%S')}\"\n",
    "\n",
    "    if not os.path.exists(f\"{PATHS['LOG_DIR']}/{_cfg['exp_id']}\"):\n",
    "        os.makedirs(f\"{PATHS['LOG_DIR']}/{_cfg['exp_id']}\")\n",
    "    setup_logging(f\"{PATHS['LOG_DIR']}/{_cfg['exp_id']}\")\n",
    "\n",
    "    import wandb\n",
    "    Logger.info('wandb imported')\n",
    "\n",
    "    t_resume = (_cfg['model'][\"resume\"] is not None) and os.path.exists(\n",
    "        get_saved_model_path(_cfg['PATHS']['CP_DIR'], _cfg['model_id']))\n",
    "    t_mode = 'online' if _cfg[\"kaggle_run_type\"] != \"batch\" and _cfg['wandb_mode'] == 'online' else 'offline'\n",
    "    Logger.info(f'resuming: {t_resume}; wandb mode: {t_mode}')\n",
    "\n",
    "    wandb.init(project=_cfg['comp_name'],\n",
    "               name=_cfg['run_id'],\n",
    "               config=_cfg,\n",
    "               dir=_cfg['PATHS']['LOG_DIR'],\n",
    "               resume=t_resume,\n",
    "               tags=[\n",
    "                   _cfg['model']['Proto'],\n",
    "                   _cfg['model']['model_type'],\n",
    "               ],\n",
    "               notes='resumed',\n",
    "               mode=t_mode)\n",
    "    del t_resume, t_mode\n",
    "\n",
    "    wandb.config['train_aug_list'] = albu.Compose(\n",
    "        get_aug_list(cfg_model['tile_size'], cfg_model['in_channels'], mode='train')).to_dict()\n",
    "    wandb.config['valid_aug_list'] = albu.Compose(\n",
    "        get_aug_list(cfg_model['tile_size'], cfg_model['in_channels'], mode='valid')).to_dict()\n",
    "\n",
    "    _cfg = wandb.config\n",
    "\n",
    "    return _cfg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:15.057204Z",
     "end_time": "2023-05-11T11:05:15.075959Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:15.067466Z",
     "end_time": "2023-05-11T11:05:15.089961Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Global cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "g_cfg = get_config()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:15.083962Z",
     "end_time": "2023-05-11T11:05:19.765217Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### External models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.769218Z",
     "end_time": "2023-05-11T11:05:19.787763Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if not g_cfg.kaggle_run_type == \"batch\":\n",
    "    # https://github.com/Cadene/pretrained-models.pytorch/issues/222\n",
    "    import ssl\n",
    "\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "if g_cfg.HOST == 'kaggle':\n",
    "    EXTERNAL_MODELS_DIR = Path(g_cfg.PATHS.EXTERNAL_MODELS_DIR)\n",
    "    sys.path.append(str(EXTERNAL_MODELS_DIR / \"segmentation-models-pytorch\" / \"segmentation_models.pytorch-master\"))\n",
    "    sys.path.append(str(EXTERNAL_MODELS_DIR / \"pretrainedmodels\" / \"pretrainedmodels-0.7.4\"))\n",
    "    sys.path.append(str(EXTERNAL_MODELS_DIR / \"efficientnet-pytorch\" / \"EfficientNet-PyTorch-master\"))\n",
    "    del EXTERNAL_MODELS_DIR\n",
    "\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    import segmentation_models_pytorch as smp\n",
    "\n",
    "else:\n",
    "    if importlib.util.find_spec(\"segmentation_models_pytorch\") is None:\n",
    "        !conda install -y segmentation-models-pytorch\n",
    "    # %%conda install -y -c conda-forge segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.781725Z",
     "end_time": "2023-05-11T11:05:19.825723Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.797725Z",
     "end_time": "2023-05-11T11:05:19.857724Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.812727Z",
     "end_time": "2023-05-11T11:05:19.873237Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    # pixels = (pixels >= thr).astype(np.uint8)\n",
    "\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# def np_rle(img):\n",
    "#     flat_img = np.where(img.flatten() , 1, 0).astype(np.uint8)\n",
    "#     starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n",
    "#     ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n",
    "#     starts_ix = np.where(starts)[0] + 2\n",
    "#     ends_ix = np.where(ends)[0] + 2\n",
    "#     lengths = ends_ix - starts_ix\n",
    "#     predicted_arr = np.stack([starts_ix, lengths]).T.flatten()\n",
    "#     rle_str=np.array2string(predicted_arr.reshape(-1), separator=' ')\n",
    "#     return rle_str[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.827726Z",
     "end_time": "2023-05-11T11:05:19.881241Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class CustomModel(nn.Module):\n",
    "#     def __init__(self, cfg):\n",
    "#         super().__init__()\n",
    "#         self.cfg = cfg\n",
    "#         self.th = None\n",
    "#         # if cfg[\"model_name\"] == \"Unet++\":\n",
    "#         #     model_Conductor=getattr(smp, \"UnetPlusPlus\")\n",
    "#         # else:\n",
    "#         #     model_Conductor=getattr(smp, cfg[\"model_name\"])\n",
    "#         # self.encoder = model_Conductor(\n",
    "#         self.encoder = getattr(smp, cfg[\"Proto\"])(**cfg['args'])\n",
    "#\n",
    "#     def forward(self, image):\n",
    "#         output = self.encoder(image)\n",
    "#         # output = output.squeeze(-1)\n",
    "#         return output\n",
    "\n",
    "\n",
    "def build_model(cfg, cp_dir=g_cfg['PATHS']['CP_DIR'],\n",
    "                model_id=g_cfg['model_id'], weight=None):\n",
    "    \"\"\"\n",
    "    DO notice that this needs a global config\n",
    "    for paths and model_id\n",
    "    \"\"\"\n",
    "    Logger.info(f\"model_cfg: {cfg}\")\n",
    "    if cfg['resume'] is not None:\n",
    "        model_path = get_saved_model_path(cp_dir, model_id)\n",
    "        if os.path.exists(model_path):\n",
    "            Logger.info(f'load model from: {model_path}')\n",
    "            _model = CustomModel(cfg)\n",
    "            loaded_model = torch.load(model_path)\n",
    "            # print(loaded_model)\n",
    "            _model.load_state_dict(loaded_model['model'])\n",
    "            # best_loss = loaded_model['best_loss']\n",
    "            # best_loss = None if loaded_model['best_loss'] is None else loaded_model['best_loss']\n",
    "            # best_loss = loaded_model['best_loss']\n",
    "            th = loaded_model['th'] if 'th' in loaded_model else 0.5\n",
    "            _model.th = th\n",
    "            return _model\n",
    "        Logger.info(f'trained model not found')\n",
    "\n",
    "    # if cfg['HOST']=='kaggle':\n",
    "    #     weight = None\n",
    "    _model = CustomModel(cfg)\n",
    "    _model.th = 0.5\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.844726Z",
     "end_time": "2023-05-11T11:05:19.882242Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# t = build_model(g_cfg['model'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.858729Z",
     "end_time": "2023-05-11T11:05:19.882242Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.875242Z",
     "end_time": "2023-05-11T11:05:19.936240Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_transforms(mode, cfg):\n",
    "    return albu.Compose(get_aug_list(cfg['tile_size'], cfg['in_channels'], mode=mode))\n",
    "\n",
    "\n",
    "from data_loader import datasets, data_loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.893242Z",
     "end_time": "2023-05-11T11:05:19.940242Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dataset(cfg, trfs_mode='train'):\n",
    "    imgset_paths = [f\"train/{i}\" for i in cfg['image_sets']]\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    labels = []\n",
    "    for path in imgset_paths:\n",
    "        imgs.append(f\"{path}/surface_volume\")\n",
    "        masks.append(f\"{path}/mask.png\")\n",
    "        labels.append(f\"{path}/inklabels.png\")\n",
    "\n",
    "    dataset = getattr(datasets, cfg['type'])(\n",
    "        image_sets=imgs,\n",
    "        cfg=cfg,\n",
    "        masks=masks,\n",
    "        labels=labels,\n",
    "        transform=get_transforms(mode=trfs_mode, cfg=cfg))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def make_data_loader(cfg, dataset):\n",
    "    loader = getattr(data_loaders, cfg['type'])(\n",
    "        dataset,\n",
    "        **cfg['args'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False)\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dataset=make_dataset(g_cfg['dataset'])\n",
    "# train_loader=make_data_loader(g_cfg['data_loader'],dataset)\n",
    "# valid_lodaer=train_loader.split_validation()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.908243Z",
     "end_time": "2023-05-11T11:05:19.940242Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.925244Z",
     "end_time": "2023-05-11T11:05:19.940242Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_optimizer(cfg, model):\n",
    "    _optimizer = getattr(torch.optim, cfg['type'])(\n",
    "        model, **cfg['args'])\n",
    "    return _optimizer\n",
    "\n",
    "\n",
    "def get_scheduler(cfg, optimizer):\n",
    "    _scheduler = getattr(LRS, cfg['type'])(\n",
    "        optimizer, **cfg['args'])\n",
    "    return _scheduler\n",
    "\n",
    "\n",
    "def scheduler_step(_scheduler):\n",
    "    _scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model,loss =build_model(g_cfg['model'],model_id=g_cfg['model_id'],cp_dir=g_cfg['PATHS']['CP_DIR'])\n",
    "# optimizer=get_optimizer(g_cfg['optimizer'],model)\n",
    "# scheduler=get_scheduler(g_cfg['scheduler'],optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.939242Z",
     "end_time": "2023-05-11T11:05:19.956243Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.953244Z",
     "end_time": "2023-05-11T11:05:19.982790Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.969286Z",
     "end_time": "2023-05-11T11:05:19.985793Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.984793Z",
     "end_time": "2023-05-11T11:05:19.999791Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T11:05:19.999791Z",
     "end_time": "2023-05-11T11:05:20.032495Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "USE Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trainer.VesuviusTrainer import VesuviusTrainer as Trainer\n",
    "\n",
    "# def main(config):\n",
    "\"\"\"\n",
    "Take global config and train model\n",
    "\"\"\"\n",
    "logger = get_logger('train')\n",
    "config = g_cfg\n",
    "# setup data_loader instances\n",
    "# trms=get_aug_list(config['model']['tile_size'],config['model']['in_channels'],'train')\n",
    "\n",
    "full_dataset = make_dataset(config['dataset'])\n",
    "data_loader = make_data_loader(config['data_loader'], full_dataset)\n",
    "\n",
    "# data_loader = config.init_obj('data_loader', module_data)\n",
    "\n",
    "valid_data_loader = data_loader.split_validation()\n",
    "\n",
    "# build model architecture, then print to console\n",
    "# model = config.init_obj('arch', module_arch)\n",
    "model = build_model(config['model'])\n",
    "# logger.info(model)\n",
    "\n",
    "# prepare for (multi-device) GPU training\n",
    "device, device_ids = prepare_device(config['n_gpu'])\n",
    "model = model.to(device)\n",
    "if len(device_ids) > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "\n",
    "# get function handles of loss and metrics\n",
    "# criterion = module_loss.config['loss'] which should be a function\n",
    "criterion = getattr(module_loss, config['loss'])\n",
    "# metrics is module_metric.__dict__[config['metrics']] which should be a list of functions\n",
    "metrics = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "# build optimizer, learning rate scheduler. delete every lines containing lr_scheduler for disabling scheduler\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\n",
    "optimizer = get_optimizer(config['optimizer'], trainable_params)\n",
    "lr_scheduler = get_scheduler(config['scheduler'], optimizer)\n",
    "\n",
    "trainer = Trainer(model, criterion, metrics, optimizer,\n",
    "                  config=config,\n",
    "                  device=device,\n",
    "                  data_loader=data_loader,\n",
    "                  valid_data_loader=valid_data_loader,\n",
    "                  lr_scheduler=lr_scheduler,\n",
    "                  len_epoch=1000)\n",
    "\n",
    "trainer.train()\n",
    "del trainer, model, optimizer, lr_scheduler, data_loader, valid_data_loader\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T15:15:35.954144Z",
     "end_time": "2023-05-10T15:35:59.287846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data_ori, target_ori = next(iter(data_loader))\n",
    "# output_ori = model(data_ori.to(device)).squeeze(1)\n",
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T23:19:51.559089Z",
     "end_time": "2023-05-10T23:20:02.821403Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# for met in metrics:\n",
    "#     print('train/' + met.__name__, met(output_ori, target_ori))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T15:00:54.079584Z",
     "end_time": "2023-05-10T15:00:54.139291Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from torchvision.utils import make_grid\n",
    "# from matplotlib import pyplot as plt\n",
    "# target=target_ori.unsqueeze(1)\n",
    "# output=output_ori.unsqueeze(1)\n",
    "#\n",
    "# fig,axs=plt.subplots(2,1)\n",
    "# axs[0].imshow(make_grid(output, nrow=8)[0].cpu().detach().numpy(),cmap='gray')\n",
    "# axs[1].imshow(make_grid(target, nrow=8)[0].cpu().detach().numpy(),cmap='gray')\n",
    "#\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T15:12:25.391534Z",
     "end_time": "2023-05-10T15:12:25.574481Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_norm, target_norm = getattr(module_metric, 'normalize')(output, target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T13:28:14.532217Z",
     "end_time": "2023-05-10T13:28:14.532217Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ctp = output_norm[target_norm == 1].sum()\n",
    "cfp = output_norm[target_norm == 0].sum()\n",
    "ctn = (~output_norm)[target_norm == 0].sum()\n",
    "cfn = (~output_norm)[target_norm == 1].sum()\n",
    "assert ctp + cfp + ctn + cfn == output_norm.numel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T13:29:27.639821Z",
     "end_time": "2023-05-10T13:29:27.639821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# output_grid = make_grid(output_tensor, nrow=8)[0].cpu().numpy()\n",
    "# target_grid = make_grid(target.unsqueeze(1), nrow=8)[0].cpu().numpy()\n",
    "# fig,axs=plt.subplots(1,2)\n",
    "# axs[0].imshow(output_grid, cmap='gray')\n",
    "# axs[1].imshow(target_grid, cmap='gray')\n",
    "#\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(g_cfg)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data, target = next(iter(data_loader))\n",
    "# output = model(data.to(device))\n",
    "# a=output[0,:,:].cpu().detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T00:48:01.448498Z",
     "end_time": "2023-05-10T00:48:32.083320Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T00:51:42.747460Z",
     "end_time": "2023-05-10T00:51:42.766460Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(a.astype(np.float32), cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T00:54:31.961674Z",
     "end_time": "2023-05-10T00:54:32.119702Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for met in metrics:\n",
    "#     print('train/' + met.__name__, met(output, target))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T00:54:45.595898Z",
     "end_time": "2023-05-10T00:54:45.674413Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import wandb\n",
    "# import torchvision.utils as vutils\n",
    "#\n",
    "# # Create a random input tensor and target tensor\n",
    "# B, C, H, W = 4, 8, 256, 256\n",
    "# input_tensor = torch.randint(low=0, high=2, size=(B, C, H, W))\n",
    "# output_tensor = torch.randint(low=0, high=2, size=(B, H, W))\n",
    "# target_tensor = torch.randint(low=0, high=2, size=(B, H, W))\n",
    "#\n",
    "# # Convert the target tensor to an RGB image\n",
    "# output_tensor = output_tensor.unsqueeze(1)\n",
    "# target_tensor = target_tensor.unsqueeze(1)\n",
    "# # target_tensor[:, 0, :, :][target_tensor[:, 0, :, :] == 1] = 255\n",
    "#\n",
    "# # Create a grid of input images and a grid of target images\n",
    "# input_grid = vutils.make_grid(input_tensor, nrow=B).numpy()\n",
    "# output_grid = vutils.make_grid(input_tensor, nrow=B).numpy()\n",
    "# target_grid = vutils.make_grid(target_tensor, nrow=B).numpy()\n",
    "#\n",
    "#\n",
    "#\n",
    "# a = wandb.Image(\n",
    "#     input_grid[0], masks={\n",
    "#         \"predictions\": {\"mask_data\": output_grid[0]},\n",
    "#         \"ground_truth\": {\"mask_data\": target_grid[0]},\n",
    "#     })\n",
    "#\n",
    "# # a.image.show()\n",
    "# a._masks['predictions']['mask_data'].show()\n",
    "# a._masks['ground_truth']['mask_data'].show()\n",
    "# # fig,axs=plt.subplots(2,1)\n",
    "# # # ax[0].imshow(input_grid[0,:,:])\n",
    "# # axs[0].imshow(input_grid, cmap='gray')\n",
    "# # axs[1].imshow(target_grid, cmap='gray')\n",
    "# # # Set the x-axis limits of all subplots\n",
    "# # # xmin = min(axs[0].get_xlim()[0], axs[1].get_xlim()[0])\n",
    "# # # xmax = max(axs[0].get_xlim()[1], axs[1].get_xlim()[1])\n",
    "# # # for ax in axs:\n",
    "# # #     ax.set_aspect('equal')\n",
    "# #     # ax.set_xlim(xmin, xmax)\n",
    "# #     # ax.set_axis_off()\n",
    "# # plt.savefig('test.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T22:56:40.999023Z",
     "end_time": "2023-05-09T22:56:40.999023Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# with tqdm(enumerate(full_dataset), total=len(full_dataset)) as pbar:\n",
    "#     for idx, (img, tar) in pbar:\n",
    "#         assert img.shape[1:] == tar.shape, f\"img.shape:{img.shape} != tar.shape:{tar.shape}\"\n",
    "#         assert img.shape[-1] == 224, f\"img.shape:{img.shape}\"\n",
    "#         assert img.dtype == tar.dtype, f\"img.dtype:{img.dtype} != tar.dtype:{tar.dtype}\"\n",
    "# break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T17:23:28.563444Z",
     "end_time": "2023-05-09T17:23:28.563444Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " ## Train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-07T15:14:36.802514Z",
     "end_time": "2023-05-07T15:14:36.836560Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "#\n",
    "#\n",
    "# def train_fn(cfg):\n",
    "#     model.train()\n",
    "#\n",
    "#     scaler = GradScaler(enabled=cfg[\"use_amp\"])\n",
    "#     losses = AverageMeter()\n",
    "#\n",
    "#     full_dataset = make_dataset(g_cfg['dataset'])\n",
    "#     train_loader = make_data_loader(g_cfg['data_loader'], full_dataset)\n",
    "#     valid_loader = train_loader.split_validation()\n",
    "#\n",
    "#     with tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
    "#         for step, data in pbar:\n",
    "#             images, masks, labels, positions = data\n",
    "#\n",
    "#             images = images.to(cfg['device'])\n",
    "#             labels = labels.to(cfg['device'])\n",
    "#             batch_size = labels.size(0)\n",
    "#\n",
    "#             with autocast(cfg[\"use_amp\"]):\n",
    "#                 y_preds = model(images).squeeze()\n",
    "#                 labels = labels.squeeze()\n",
    "#\n",
    "#                 loss = criterion(y_preds, labels)\n",
    "#                 assert loss > 0, f'input should be 0-1, but got: labels: {labels.min()}-{labels.max()}, y_preds: {y_preds.min()}-{y_preds.max()}'\n",
    "#\n",
    "#             losses.update(loss.item(), batch_size)\n",
    "#             scaler.scale(loss).backward()\n",
    "#\n",
    "#             grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "#                 model.parameters(), cfg[\"max_grad_norm\"])\n",
    "#\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "#             optimizer.zero_grad()\n",
    "#\n",
    "#     return losses.avg\n",
    "#\n",
    "#\n",
    "# def valid_fn(cfg, valid_loader):\n",
    "#     label_pred = np.zeros(valid_mask_gt.shape)\n",
    "#     label_count = np.zeros(valid_mask_gt.shape)\n",
    "#\n",
    "#     model.eval()\n",
    "#     losses = AverageMeter(mode='valid')\n",
    "#\n",
    "#     with tqdm(enumerate(valid_loader), total=len(valid_loader)) as pbar:\n",
    "#         for step, (images, masks, labels, positions) in pbar:\n",
    "#\n",
    "#             images = images.to(cfg['device'])\n",
    "#             labels = labels.to(cfg['device'])\n",
    "#             batch_size = labels.size(0)\n",
    "#\n",
    "#             with torch.no_grad():\n",
    "#                 y_preds = model(images).squeeze()\n",
    "#                 labels = labels.squeeze()\n",
    "#                 loss = criterion(y_preds, labels)\n",
    "#                 assert loss > 0, f'input should be 0-1, but got: labels: {labels.min()}-{labels.max()}, y_preds: {y_preds.min()}-{y_preds.max()}'\n",
    "#             losses.update(loss.item(), batch_size)\n",
    "#\n",
    "#             # make whole mask\n",
    "#             y_preds = torch.sigmoid(y_preds).to('cpu').numpy()\n",
    "#             # start_idx = step*CONFIG[\"valid_batch_size\"]             # end_idx = start_idx + batch_size\n",
    "#             # print(positions)\n",
    "#             for i, (x1, y1, x2, y2) in enumerate(zip(*positions)):\n",
    "#                 label_pred[y1:y2, x1:x2] += y_preds[i]\n",
    "#                 label_count[y1:y2, x1:x2] += np.ones((y2 - y1, x2 - x1))\n",
    "#\n",
    "#     Logger.info(f'mask_count_min: {label_count.min()}')\n",
    "#     label_pred /= label_count + 1e-8\n",
    "#     return losses.avg, label_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-07T15:14:36.813530Z",
     "end_time": "2023-05-07T15:14:36.837560Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "# TODO : modify test_fn\n",
    "# seems it more like to use loader than single image\n",
    "# consider tiled and stack?\n",
    "def test_fn(test_img, model, device, mask_gt, tile_size=224):\n",
    "    assert test_img.shape[1:3] == mask_gt.shape[0:2]\n",
    "    model.eval()\n",
    "    label_pred = np.zeros(mask_gt.shape)\n",
    "    label_count = np.zeros(mask_gt.shape)\n",
    "\n",
    "    ori_x, ori_y = mask_gt.shape\n",
    "    if mask_gt.max() > 1:\n",
    "        mask_gt = mask_gt / 255\n",
    "\n",
    "    pad0 = (tile_size - ori_x % tile_size) % tile_size\n",
    "    pad1 = (tile_size - ori_y % tile_size) % tile_size\n",
    "    tiled_img = np.pad(test_img, [[0, 0], [0, pad0], [0, pad1]], constant_values=0)\n",
    "    tiled_mask = np.pad(mask_gt, [[0, pad0], [0, pad1]], constant_values=0)\n",
    "\n",
    "    tiled_img = torch.from_numpy(tiled_img).float()\n",
    "    tiled_mask = torch.from_numpy(tiled_mask).float()\n",
    "\n",
    "    nx = (ori_x + pad0) // tile_size\n",
    "    ny = (ori_y + pad1) // tile_size\n",
    "\n",
    "    for x, y in itertools.product(range(nx), range(ny)):\n",
    "        x1 = int(x * tile_size)\n",
    "        x2 = int(x * tile_size + tile_size)\n",
    "        y1 = int(y * tile_size)\n",
    "        y2 = int(y * tile_size + tile_size)\n",
    "\n",
    "        img = tiled_img[:, x1:x2, y1:y2]\n",
    "\n",
    "        img = img.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(img).squeeze()\n",
    "\n",
    "        label_pred[x1:x2, y1:y2] += y_preds > model.th\n",
    "        label_count[x1:x2, y1:y2] += np.ones((tile_size, tile_size))\n",
    "\n",
    "    label_pred /= label_count + 1e-8\n",
    "    label_pred *= mask_gt\n",
    "\n",
    "    return label_pred[:ori_x, :ori_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-07T15:14:36.832043Z",
     "end_time": "2023-05-07T15:14:36.843563Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # TODO : modify EarlyStopping\n",
    "# # add detection of val_loss\n",
    "# class EarlyStopping:\n",
    "#     def __init__(self, patience=7, verbose=False, delta=0):\n",
    "#         self.patience = patience\n",
    "#         self.verbose = verbose\n",
    "#         self.counter = 0\n",
    "#         self.best_score = None\n",
    "#         self.early_stop = False\n",
    "#         self.val_loss_min = None\n",
    "#         self.delta = delta\n",
    "#\n",
    "#     def __call__(self, score, val_loss, model):\n",
    "#\n",
    "#         if self.best_score is None:\n",
    "#             self.best_score = score\n",
    "#             self.save_checkpoint(score, val_loss, model)\n",
    "#             return\n",
    "#\n",
    "#         if score > self.best_score + self.delta:\n",
    "#             self.save_checkpoint(score, val_loss, model)\n",
    "#             self.counter = 0\n",
    "#             return\n",
    "#         else:\n",
    "#             self.counter += 1\n",
    "#             Logger.info(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "#             if self.counter >= self.patience:\n",
    "#                 self.early_stop = True\n",
    "#\n",
    "#     def save_checkpoint(self, score, val_loss, model):\n",
    "#         \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "#\n",
    "#         if self.verbose:\n",
    "#             # Logger.info(\n",
    "#             #     f\"Validation loss decreased ({self.val_loss_min:.6f} --> {score:.6f}).  Saving model ...\"\n",
    "#             # )\n",
    "#             Logger.info(\n",
    "#                 f\"Validation score increased ({self.best_score:.6f} --> {score:.6f}).  Saving model ...\")\n",
    "#         save_path = get_saved_model_path(g_cfg)\n",
    "#         if os.path.exists(save_path):\n",
    "#             shutil.move(save_path, save_path.replace('.pt', '-bkp.pt'))\n",
    "#         self.val_loss_min = val_loss\n",
    "#         self.best_score = score\n",
    "#         torch.save(\n",
    "#             {\"model\": model.state_dict(),\n",
    "#              \"best_score\": score,\n",
    "#              \"best_loss\": val_loss,\n",
    "#              \"th\": model.th\n",
    "#              }\n",
    "#             , save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preparation\n",
    "### prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-07T15:14:36.847596Z",
     "end_time": "2023-05-07T15:14:36.880680Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def create_foldset():\n",
    "#     foldset = []\n",
    "#     foldset.append({\n",
    "#         'train': [1, 2],\n",
    "#         'valid': [3]\n",
    "#     })\n",
    "#     foldset.append({\n",
    "#         'train': [1, 3],\n",
    "#         'valid': [2]\n",
    "#     })\n",
    "#     foldset.append({\n",
    "#         'train': [2, 3],\n",
    "#         'valid': [1]\n",
    "#     })\n",
    "#     return foldset\n",
    "# #\n",
    "#\n",
    "# def get_best_score(metric_direction):\n",
    "#     if metric_direction == 'minimize':\n",
    "#         return np.inf\n",
    "#     elif metric_direction == 'maximize':\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "#\n",
    "#\n",
    "# def should_update_best_score(metric_direction, score, best_score):\n",
    "#     if metric_direction == 'minimize':\n",
    "#         return score < best_score\n",
    "#     elif metric_direction == 'maximize':\n",
    "#         return score > best_score\n",
    "#\n",
    "#\n",
    "# def preprocess_valid_mask_gt(valid_mask_gt, tile_size):\n",
    "#     if valid_mask_gt.max() > 1:\n",
    "#         Logger.info(f'valid_mask_gt.shape: {valid_mask_gt.shape} \\n'\n",
    "#                     f'valid_mask_gt.max: {valid_mask_gt.max()} \\n')\n",
    "#         valid_mask_gt = valid_mask_gt / 255\n",
    "#\n",
    "#     pad0 = (tile_size - valid_mask_gt.shape[0] % tile_size)\n",
    "#     pad1 = (tile_size - valid_mask_gt.shape[1] % tile_size)\n",
    "#     valid_mask_gt = np.pad(valid_mask_gt, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "#\n",
    "#     return valid_mask_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### wandb for trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T13:01:16.796074Z",
     "start_time": "2023-04-28T13:01:16.796074Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#    fold_configs = create_foldset()\n",
    "Logger.info(g_cfg)\n",
    "\n",
    "model, best_loss = build_model(g_cfg['model'],\n",
    "                               model_id=g_cfg['model_id'],\n",
    "                               cp_dir=g_cfg['PATHS']['CP_DIR'])\n",
    "best_loss = np.inf if best_loss is None else best_loss\n",
    "model.to(g_cfg.device)\n",
    "\n",
    "if g_cfg['run_mode'] == 'train':\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=g_cfg.Patience, verbose=True\n",
    "    )\n",
    "    for epoch in range(g_cfg[\"epochs\"]):\n",
    "        optimizer = get_optimizer(g_cfg['optimizer'], model)\n",
    "        scheduler = get_scheduler(g_cfg['scheduler'], optimizer)\n",
    "\n",
    "        dataset = make_dataset(g_cfg['dataset'])\n",
    "\n",
    "        valid_mask_gt = valid_loader.dataset.get_gt(0)\n",
    "\n",
    "        valid_mask_gt = preprocess_valid_mask_gt(valid_mask_gt, g_cfg[\"tile_size\"])\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, label_pred = valid_fn(\n",
    "            valid_loader, model, criterion, device, valid_mask_gt)\n",
    "\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            Logger.info(f'best_loss: {best_loss:.4f}')\n",
    "            torch.save(model.state_dict(), get_saved_model_path(g_cfg))\n",
    "\n",
    "        scheduler_step(scheduler, avg_val_loss, epoch)\n",
    "\n",
    "        best_dice, best_th = calc_cv(valid_mask_gt, label_pred)\n",
    "\n",
    "        model.th = best_th\n",
    "\n",
    "        # score = avg_val_loss\n",
    "        score = best_dice\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        early_stopping(score, avg_val_loss, model)\n",
    "\n",
    "        Logger.info(\n",
    "            f'Epoch {epoch + 1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        Logger.info(\n",
    "            f'Epoch {epoch + 1} - avgScore: {score:.4f}')\n",
    "        if USE_WANDB:\n",
    "            wandb.log({\n",
    "                \"train_loss\": avg_loss,\n",
    "                \"val_loss\": avg_val_loss,\n",
    "                \"best_dice\": best_dice,\n",
    "                \"best_th\": best_th,\n",
    "                \"best_loss\": best_loss,\n",
    "            })\n",
    "        if early_stopping.early_stop:\n",
    "            Logger.info(\"Early stopping\")\n",
    "            break\n",
    "    if early_stopping.early_stop:\n",
    "        Logger.info(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "del model, optimizer, scheduler, early_stopping, train_loader, valid_loader, valid_mask_gt, label_pred\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T13:01:23.072760Z",
     "start_time": "2023-04-28T13:01:23.071760Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "results = []\n",
    "for id in ['a', 'b']:\n",
    "    test_img = ImgLoader.load_from_path_static(\n",
    "        cache_dir=g_cfg['cache_dir'],\n",
    "        data_dir=g_cfg['data_dir'],\n",
    "        file_path=f\"test/{id}/surface_volume\",\n",
    "    )\n",
    "\n",
    "    mask = ImgLoader.load_from_path_static(\n",
    "        cache_dir=g_cfg['cache_dir'],\n",
    "        data_dir=g_cfg['data_dir'],\n",
    "        file_path=f\"test/{id}/mask.png\",\n",
    "    )\n",
    "    test_img = np.moveaxis(test_img, -1, 0)\n",
    "\n",
    "    model, best_loss = build_model(g_cfg)\n",
    "    model.to(device)\n",
    "    label_pred = test_fn(test_img, model, device, mask, g_cfg['tile_size'])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    ax[0].imshow(test_img)\n",
    "    ax[1].imshow(label_pred)\n",
    "    ax[2].imshow(mask)\n",
    "    ax[0].set_title('test_img')\n",
    "    ax[1].set_title('label_pred')\n",
    "    ax[2].set_title('mask')\n",
    "\n",
    "    plt.show()\n",
    "    results.append((id, label_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(results, columns=['Id', 'Predicted'])\n",
    "sub.Id = sub.Id.asytpe(str)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv(g_cfg['comp_dataset_path'] / 'sample_submission.csv')\n",
    "sample_sub = pd.merge(sample_sub[['Id']], sub, on='Id', how='left')\n",
    "sample_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
