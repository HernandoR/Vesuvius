{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "import importlib.util\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as albu\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import lr_scheduler as LRS, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:18.860501Z",
     "end_time": "2023-04-24T20:21:18.860679Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configs\n",
    "### Env detection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "HOST = socket.gethostname()\n",
    "\n",
    "# noinspection PyUnresolvedReferences\n",
    "is_kaggle = _dh == [\"/kaggle/working\"]\n",
    "\n",
    "is_test = True\n",
    "\n",
    "is_train = False\n",
    "\n",
    "is_to_submit = False\n",
    "\n",
    "exp_id = \"Unet++_2.5d_Unimodel\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:18.868902Z",
     "end_time": "2023-04-24T20:21:18.869041Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Auto settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date_time = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_id = exp_id + \"_\" + date_time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      else \"mps\" if torch.backends.mps.is_available()\n",
    "else \"cpu\")\n",
    "\n",
    "if is_test:\n",
    "    is_train = False\n",
    "    is_to_submit = False\n",
    "    exp_id = exp_id + \"_test\"\n",
    "    run_id = exp_id + \"_\" + date_time\n",
    "\n",
    "USE_WANDB = False\n",
    "\n",
    "exp_id, HOST, is_kaggle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:18.940263Z",
     "end_time": "2023-04-24T20:21:18.940334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not is_kaggle:\n",
    "    ROOT_DIR = Path(\"../\").absolute()\n",
    "    DATA_DIR = ROOT_DIR / \"data\" / \"raw\"\n",
    "    OUTPUT_DIR = ROOT_DIR / \"saved\"\n",
    "    CP_DIR = OUTPUT_DIR / \"checkpoints\"\n",
    "    LOG_DIR = ROOT_DIR / \"saved\" / \"logs\"\n",
    "    CACHE_DIR = ROOT_DIR / \"saved\" / \"cache\"\n",
    "    EXTERNAL_MODELS_DIR = ROOT_DIR / \"model\"\n",
    "else:\n",
    "    ROOT_DIR = Path(\"/kaggle\")\n",
    "    DATA_DIR = ROOT_DIR / \"input\" / \"vesuvius-challenge-ink-detection\"\n",
    "    OUTPUT_DIR = ROOT_DIR / \"working\"\n",
    "    CP_DIR = OUTPUT_DIR / \"ink-model\"\n",
    "    LOG_DIR = OUTPUT_DIR / \"saved\" / \"logs\"\n",
    "    CACHE_DIR = OUTPUT_DIR / \"saved\" / \"cache\"\n",
    "    EXTERNAL_MODELS_DIR = ROOT_DIR / \"input\"\n",
    "\n",
    "print(f\"ROOT_DIR: {ROOT_DIR}\")\n",
    "\n",
    "for p in [ROOT_DIR, DATA_DIR, OUTPUT_DIR, CP_DIR, LOG_DIR, CACHE_DIR]:\n",
    "    if os.path.exists(p) is False:\n",
    "        os.makedirs(p)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:18.940470Z",
     "end_time": "2023-04-24T20:21:18.940499Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### set Logger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def init_logger(log_file):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "\n",
    "    # remove existing handlers\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:18.940554Z",
     "end_time": "2023-04-24T20:21:18.940578Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Logger = init_logger(log_file=str(LOG_DIR / run_id) + '.log')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:18.940630Z",
     "end_time": "2023-04-24T20:21:18.940653Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### External models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not is_to_submit:\n",
    "    # https://github.com/Cadene/pretrained-models.pytorch/issues/222\n",
    "    import ssl\n",
    "\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "if is_kaggle:\n",
    "    sys.path.append(str(EXTERNAL_MODELS_DIR / \"segmentation-models-pytorch\" / \"segmentation_models.pytorch-master\"))\n",
    "    sys.path.append(str(EXTERNAL_MODELS_DIR / \"pretrainedmodels\" / \"pretrainedmodels-0.7.4\"))\n",
    "    sys.path.append(str(EXTERNAL_MODELS_DIR / \"efficientnet-pytorch\" / \"EfficientNet-PyTorch-master\"))\n",
    "\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    import segmentation_models_pytorch as smp\n",
    "\n",
    "else:\n",
    "    if importlib.util.find_spec(\"segmentation_models_pytorch\") is None:\n",
    "        !conda install -y segmentation-models-pytorch\n",
    "    import segmentation_models_pytorch as smp\n",
    "    # %%conda install -y -c conda-forge segmentation-models-pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.112182Z",
     "end_time": "2023-04-24T20:21:21.112332Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## configs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Config:\n",
    "    comp_name = \"vesuvius\"\n",
    "    # ============== path =============\n",
    "    comp_dataset_path = DATA_DIR  # dataset path\n",
    "    cache_dir = CACHE_DIR  # cache directory\n",
    "    data_dir = DATA_DIR  # data directory\n",
    "    LOG_DIR = LOG_DIR  # log directory\n",
    "    Note_book = exp_id  # notebook name\n",
    "    model_dir = CP_DIR  # model directory\n",
    "    exp_name = exp_id  # experiment name\n",
    "    run_id = run_id  # run id\n",
    "    HOST = HOST  # host name\n",
    "\n",
    "    # ============== pred target =============\n",
    "    target_size = 1  # prediction target size\n",
    "\n",
    "    # ============== model cfg =============\n",
    "    model_name = \"Unet++\"  # model name\n",
    "    backbone = \"se_resnext50_32x4d\"  # model backbone\n",
    "    in_channels = 6  # number of input channels\n",
    "    resume = True  # resume training\n",
    "\n",
    "    # ============== training cfg =============\n",
    "    size = 224  # image size\n",
    "    tile_size = 224  # tile size\n",
    "    stride = 56  # tile stride\n",
    "\n",
    "    batch_size = 16  # batch size\n",
    "    use_amp = True  # use automatic mixed precision\n",
    "\n",
    "    scheduler = \"GradualWarmupSchedulerV2\"  # learning rate scheduler\n",
    "    epochs = 20  # number of training epochs\n",
    "    PATIENCE = min(epochs // 2, 8)  # early stopping patience\n",
    "    warmup_factor = 10  # warmup factor\n",
    "    lr = 1e-5 / 10  # initial learning rate\n",
    "\n",
    "    # ============== fold =============\n",
    "    valid_id = 2  # validation fold id\n",
    "\n",
    "    objective_cv = \"binary\"  # objective type\n",
    "    metric_direction = \"maximize\"  # metric direction\n",
    "\n",
    "    # ============== fixed =============\n",
    "    pretrained = True  # use pre-trained weights\n",
    "    inf_weight = \"best\"  # inference weight\n",
    "\n",
    "    min_lr = 1e-6  # minimum learning rate\n",
    "    weight_decay = 1e-6  # weight decay\n",
    "    max_grad_norm = 1000  # maximum gradient norm\n",
    "\n",
    "    print_freq = 50  # print frequency\n",
    "    num_workers = 2  # number of workers\n",
    "    seed = 3407  # random seed\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return getattr(self, item)\n",
    "\n",
    "\n",
    "_Config = Config()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.125535Z",
     "end_time": "2023-04-24T20:21:21.125672Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CONFIG = {}\n",
    "for k in dir(_Config):\n",
    "    if not k.startswith(\"__\"):\n",
    "        CONFIG[k] = getattr(_Config, k)\n",
    "\n",
    "## check\n",
    "for k in CONFIG.keys():\n",
    "    if k not in CONFIG.keys():\n",
    "        print(f\"{k} is not in CONFIG\")\n",
    "    elif CONFIG[k] != CONFIG[k]:\n",
    "        print(f\"CONFIG {k} = {CONFIG[k]};is not equal to tmp {k} = {CONFIG[k]}\")\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "for k in CONFIG.keys():\n",
    "    if k not in CONFIG.keys():\n",
    "        print(f\"{k} is not in Config\")\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "cfg = CONFIG"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.133064Z",
     "end_time": "2023-04-24T20:21:21.133191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# ============== augmentation =============\n",
    "def get_aug_list(size, in_channels, type='train'):\n",
    "    \"\"\"\n",
    "    type: train, valid\n",
    "    return: list of albumentations\n",
    "\n",
    "    in case of any further modification,\n",
    "    one should use albu.Compose by themselves\n",
    "    \"\"\"\n",
    "    train_aug_list = [\n",
    "        # A.RandomResizedCrop(\n",
    "        #     size, size, scale=(0.85, 1.0)),\n",
    "        albu.Resize(size, size),\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.5),\n",
    "        albu.RandomBrightnessContrast(p=0.75),\n",
    "        albu.ShiftScaleRotate(p=0.75),\n",
    "        albu.OneOf([\n",
    "            albu.GaussNoise(var_limit=(10.0, 50.0)),\n",
    "            albu.GaussianBlur(),\n",
    "            albu.MotionBlur(),\n",
    "        ], p=0.4),\n",
    "        albu.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        albu.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3),\n",
    "                           mask_fill_value=0, p=0.5),\n",
    "        # A.Cutout(max_h_size=int(size * 0.6),\n",
    "        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "        albu.Normalize(\n",
    "            mean=[0] * in_channels,\n",
    "            std=[1] * in_channels\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "\n",
    "    valid_aug_list = [\n",
    "        albu.Resize(size, size),\n",
    "        albu.Normalize(\n",
    "            mean=[0] * in_channels,\n",
    "            std=[1] * in_channels\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "\n",
    "    if type == 'train':\n",
    "        return train_aug_list\n",
    "    else:\n",
    "        return valid_aug_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.198721Z",
     "end_time": "2023-04-24T20:21:21.198830Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### wandb for trainning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "# disable output of this cell\n",
    "\n",
    "import importlib\n",
    "\n",
    "if is_train and not is_to_submit:\n",
    "    if importlib.util.find_spec(\"wandb\") is None:\n",
    "        pass\n",
    "    else:\n",
    "        import wandb\n",
    "\n",
    "        wandb.init(project=cfg['comp_name'], name=cfg['run_id'],\n",
    "                   config=CONFIG, dir=LOG_DIR)\n",
    "\n",
    "        wandb.config['train_aug_list'] = albu.Compose(\n",
    "            get_aug_list(cfg['size'], cfg['in_channels'], type='train')).to_dict()\n",
    "        wandb.config['valid_aug_list'] = albu.Compose(\n",
    "            get_aug_list(cfg['size'], cfg['in_channels'], type='valid')).to_dict()\n",
    "        USE_WANDB = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.198945Z",
     "end_time": "2023-04-24T20:21:21.199004Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    # pixels = (pixels >= thr).astype(int)\n",
    "\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# def np_rle(img):\n",
    "#     flat_img = np.where(img.flatten() , 1, 0).astype(np.uint8)\n",
    "#     starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n",
    "#     ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n",
    "#     starts_ix = np.where(starts)[0] + 2\n",
    "#     ends_ix = np.where(ends)[0] + 2\n",
    "#     lengths = ends_ix - starts_ix\n",
    "#     predicted_arr = np.stack([starts_ix, lengths]).T.flatten()\n",
    "#     rle_str=np.array2string(predicted_arr.reshape(-1), separator=' ')\n",
    "#     return rle_str[1:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.199509Z",
     "end_time": "2023-04-24T20:21:21.199552Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, weight=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.th = None\n",
    "        self.encoder = smp.UnetPlusPlus(\n",
    "            encoder_name=cfg['backbone'],\n",
    "            encoder_weights=weight,\n",
    "            in_channels=cfg['in_channels'],\n",
    "            classes=cfg['target_size'],\n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        output = self.encoder(image)\n",
    "        # output = output.squeeze(-1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def get_saved_model_path(cfg, fold=1):\n",
    "    return str(cfg['model_dir']) + f'{cfg[\"model_name\"]}_best.pth'\n",
    "\n",
    "\n",
    "def build_model(cfg, weight=\"imagenet\"):\n",
    "    Logger.info(f\"model_name: {cfg['model_name']}\")\n",
    "    Logger.info(f\"backbone: {cfg['backbone']}\")\n",
    "    if cfg['resume']:\n",
    "        model_path = get_saved_model_path(cfg)\n",
    "        if os.path.exists(model_path):\n",
    "            Logger.info(f'load model from: {model_path}')\n",
    "            _model = CustomModel(cfg, weight=None)\n",
    "            loaded_model = torch.load(model_path)\n",
    "            # print(loaded_model)\n",
    "            _model.load_state_dict(loaded_model['model'])\n",
    "            # best_loss = loaded_model['best_loss']\n",
    "            # best_loss = None if loaded_model['best_loss'] is None else loaded_model['best_loss']\n",
    "            best_loss = loaded_model['best_loss']\n",
    "            th = loaded_model['th'] if 'th' in loaded_model else 0.5\n",
    "            _model.th = th\n",
    "            return _model, best_loss\n",
    "        Logger.info(f'trained model not found')\n",
    "\n",
    "    if is_kaggle:\n",
    "        weight = None\n",
    "    _model = CustomModel(cfg, weight)\n",
    "    return _model, None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.199622Z",
     "end_time": "2023-04-24T20:21:21.199648Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataSet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_transforms(mode, cfg):\n",
    "    return albu.Compose(get_aug_list(cfg['size'], cfg['in_channels'], type=mode))\n",
    "\n",
    "\n",
    "if not is_kaggle:\n",
    "    from DataSets import CustomDataset,ImgLoader\n",
    "else:\n",
    "    import itertools\n",
    "    from cachetools import FIFOCache, cached\n",
    "\n",
    "\n",
    "    class ImgLoader:\n",
    "\n",
    "        def __init__(self, cache_dir: Path = None, data_dir: Path = None):\n",
    "            self.cache_dir = cache_dir\n",
    "            self.data_dir = data_dir\n",
    "\n",
    "        def load_from_path(self, file_path: str = None, channel=6, tile_size=224):\n",
    "            ori_img = ImgLoader.load_from_path_static(self.cache_dir, self.data_dir, file_path, channel=channel)\n",
    "            # pad_h = (tile_size - ori_img.shape[1] % tile_size) % tile_size\n",
    "            # img = np.pad(ori_img, ((0, 0), (0, pad_h), (0, pad_w)), mode='constant')\n",
    "            # pad_w = (tile_size - ori_img.shape[2] % tile_size) % tile_size\n",
    "\n",
    "            return ori_img\n",
    "\n",
    "        @staticmethod\n",
    "        @cached(cache=FIFOCache(maxsize=10))\n",
    "        def load_from_path_static(cache_dir: Path = None, data_dir: Path = None, file_path: str = None, channel=6):\n",
    "            assert isinstance(file_path, (str, Path)), f\"file path {file_path} is not a string or Path\"\n",
    "            if isinstance(file_path, Path):\n",
    "                file_path = str(file_path)\n",
    "\n",
    "            assert not file_path.endswith('npy'), f\"file path {file_path} is a npy file\"\n",
    "            assert os.path.exists(data_dir / file_path), f\"file path {file_path} does not exist\"\n",
    "\n",
    "            path__npy_ = cache_dir / f\"{file_path}.npy\"\n",
    "\n",
    "            if os.path.exists(path__npy_):\n",
    "                img_l = np.load(str(path__npy_), allow_pickle=True)\n",
    "                assert img_l is not None, f\"Cached file {path__npy_} is None\"\n",
    "                return img_l\n",
    "\n",
    "            if not os.path.exists(path__npy_.parent):\n",
    "                os.makedirs(path__npy_.parent)\n",
    "\n",
    "            if os.path.isfile(data_dir / file_path):\n",
    "                img_l = cv2.imread(str(data_dir / file_path), 0)\n",
    "                assert img_l is not None, f\"Image file {data_dir / file_path} is None\"\n",
    "                np.save(str(path__npy_), img_l)\n",
    "                return img_l\n",
    "\n",
    "            if os.path.isdir(data_dir / file_path):\n",
    "                path__npy_ = cache_dir / f\"{file_path}_{channel}.npy\"\n",
    "                if os.path.exists(path__npy_):\n",
    "                    img_l = np.load(str(path__npy_), allow_pickle=True)\n",
    "                    assert img_l is not None, f\"Cached file {path__npy_} is None\"\n",
    "                    return img_l\n",
    "\n",
    "                img_l = []\n",
    "                files = os.listdir(data_dir / file_path)\n",
    "                mid = len(files) // 2\n",
    "                start = mid - channel // 2\n",
    "                end = mid + channel // 2\n",
    "                assert start >= 0, f\"start {start} is less than 0\"\n",
    "                assert end <= len(files), f\"end {end} is greater than {len(files)}\"\n",
    "\n",
    "                files = files[start:end]\n",
    "                for file in files:\n",
    "                    img_l.append(ImgLoader.load_from_path_static(cache_dir, data_dir, f\"{file_path}/{file}\"))\n",
    "\n",
    "                img_l = np.stack(img_l, axis=2)\n",
    "                np.save(str(path__npy_), img_l)\n",
    "                return img_l\n",
    "\n",
    "\n",
    "    class CustomDataset(Dataset):\n",
    "        \"\"\"\"\n",
    "        Custom Dataset for loading images, masks, and labels\n",
    "        params:\n",
    "            image_sets: list of image paths\n",
    "            masks: list of mask paths\n",
    "            labels: list of label paths\n",
    "            transform: albumentations transform\n",
    "            mode: train, valid, or test\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, image_sets, cfg, masks=None, labels=None, transform=None, mode=\"train\"):\n",
    "            self.image_sets = image_sets\n",
    "            self.cfg = cfg\n",
    "            self.masks = masks\n",
    "            self.labels = labels\n",
    "            self.transform = transform\n",
    "            self.type = mode\n",
    "            self.imgLoader = None\n",
    "            self.patch_pos = []\n",
    "            self.preprocess()\n",
    "\n",
    "        def preprocess(self):\n",
    "            if self.imgLoader is None:\n",
    "                self.imgLoader = ImgLoader(\n",
    "                    cache_dir=self.cfg['cache_dir'],\n",
    "                    data_dir=self.cfg['data_dir'])\n",
    "\n",
    "            for mask in self.masks:\n",
    "                # mask may be path like or numpy array\n",
    "                # if isinstance(mask, (str, Path)):\n",
    "                mask = self.imgLoader.load_from_path(mask)\n",
    "\n",
    "                x1_num = math.ceil((mask.shape[1] - self.cfg['tile_size']) / self.cfg['stride']) + 1\n",
    "                y1_num = math.ceil((mask.shape[0] - self.cfg['tile_size']) / self.cfg['stride']) + 1\n",
    "                posit = []\n",
    "                for x, y in itertools.product(range(x1_num), range(y1_num)):\n",
    "                    x, y = x * self.cfg['stride'], y * self.cfg['stride']\n",
    "                    if mask[y:y + self.cfg['tile_size'], x:x + self.cfg['tile_size']].sum() > 0:\n",
    "                        posit.append((x, y))\n",
    "                self.patch_pos.append(posit)\n",
    "\n",
    "            self.patch_pos = np.array(self.patch_pos)\n",
    "\n",
    "        def get_gt(self, img_idx):\n",
    "            return self.imgLoader.load_from_path(self.labels[img_idx])\n",
    "\n",
    "        def get_mask(self, img_idx):\n",
    "            return self.imgLoader.load_from_path(self.masks[img_idx])\n",
    "\n",
    "        def __len__(self):\n",
    "            return sum([len(posit) for posit in self.patch_pos])\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            # x1, y1, x2, y2 = self.xyxys[idx]\n",
    "            img_id = 0\n",
    "            patch_id = idx\n",
    "            for i, posit_list in enumerate(self.patch_pos):\n",
    "                if patch_id < len(posit_list):\n",
    "                    img_id = i\n",
    "                    break\n",
    "                else:\n",
    "                    patch_id -= len(posit_list)\n",
    "\n",
    "            # x1_num, y1_num = self.patch_pos[img_id]\n",
    "            # x1 = (patch_id % x1_num) * self.cfg['stride']\n",
    "            # y1 = (patch_id // x1_num) * self.cfg['stride']\n",
    "            x1, y1 = self.patch_pos[img_id][patch_id]\n",
    "            x2 = x1 + self.cfg['tile_size']\n",
    "            y2 = y1 + self.cfg['tile_size']\n",
    "\n",
    "            img = self.imgLoader.load_from_path(self.image_sets[img_id], channel=self.cfg['in_channels'])\n",
    "            mask = self.imgLoader.load_from_path(self.masks[img_id])\n",
    "\n",
    "            img = img[y1:y2, x1:x2]\n",
    "            mask = mask[y1:y2, x1:x2]\n",
    "\n",
    "            if img.shape[0] != self.cfg['tile_size'] or img.shape[1] != self.cfg['tile_size']:\n",
    "                pad_h = self.cfg['tile_size'] - img.shape[0]\n",
    "                pad_w = self.cfg['tile_size'] - img.shape[1]\n",
    "                img = np.pad(img, ((0, pad_h), (0, pad_w), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "                mask = np.pad(mask, ((0, pad_h), (0, pad_w)), mode=\"constant\", constant_values=0)\n",
    "\n",
    "            if self.type in [\"train\", \"valid\"]:\n",
    "                label = self.imgLoader.load_from_path(self.labels[img_id])\n",
    "                label = label[y1:y2, x1:x2]\n",
    "                if label.shape[0] != self.cfg['tile_size'] or label.shape[1] != self.cfg['tile_size']:\n",
    "                    pad_h = self.cfg['tile_size'] - label.shape[0]\n",
    "                    pad_w = self.cfg['tile_size'] - label.shape[1]\n",
    "                    label = np.pad(label, ((0, pad_h), (0, pad_w)), mode=\"constant\", constant_values=0)\n",
    "\n",
    "                data = self.transform(image=img, mask=mask, label=label)\n",
    "                label = data[\"label\"].astype(np.float32)\n",
    "            else:\n",
    "                label = -1\n",
    "                data = self.transform(image=img, mask=mask)\n",
    "\n",
    "            image = data[\"image\"]\n",
    "            mask = data[\"mask\"]\n",
    "\n",
    "            return image, mask, label, (x1, y1, x2, y2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.299368Z",
     "end_time": "2023-04-24T20:21:21.299549Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_dataset(img_set_ids, mode='train', dataset_mode='train'):\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    labels = []\n",
    "    for set_id in img_set_ids:\n",
    "        imgs.append(f\"{mode}/{set_id}/surface_volume\")\n",
    "        masks.append(f\"{mode}/{set_id}/mask.png\")\n",
    "        labels.append(f\"{mode}/{set_id}/inklabels.png\")\n",
    "\n",
    "    dataset = CustomDataset(\n",
    "        image_sets=imgs,\n",
    "        cfg=cfg,\n",
    "        masks=masks,\n",
    "        labels=labels,\n",
    "        mode=dataset_mode,\n",
    "        transform=get_transforms(mode=dataset_mode, cfg=cfg))\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=cfg['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=cfg['num_workers'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False)\n",
    "\n",
    "    return loader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.300209Z",
     "end_time": "2023-04-24T20:21:21.300320Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scheduler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def get_scheduler(cfg, optimizer):\n",
    "    scheduler_cosine = LRS.CosineAnnealingLR(\n",
    "        optimizer, cfg[\"epochs\"], eta_min=1e-7)\n",
    "    # scheduler = GradualWarmupSchedulerV2(\n",
    "    #     optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n",
    "\n",
    "    return scheduler_cosine\n",
    "\n",
    "\n",
    "def scheduler_step(scheduler, avg_val_loss, epoch):\n",
    "    # scheduler.step(epoch)\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.300418Z",
     "end_time": "2023-04-24T20:21:21.300444Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assessments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def fbeta_numpy(targets, preds, beta=0.5, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n",
    "    \"\"\"\n",
    "    assert all(np.unique(targets) == [0, 1]), f'mask.unique():{np.unique(targets)} != [0, 1]'\n",
    "    assert all(np.unique(preds) == [0, 1]), f'mask_pred.unique():{np.unique(preds)} != [0, 1]'\n",
    "    y_true_count = targets.sum()\n",
    "    ctp = preds[targets == 1].sum()\n",
    "    cfp = preds[targets == 0].sum()\n",
    "    beta_squared = beta * beta\n",
    "\n",
    "    c_precision = ctp / (ctp + cfp + smooth)\n",
    "    c_recall = ctp / (y_true_count + smooth)\n",
    "    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n",
    "\n",
    "    return dice\n",
    "\n",
    "\n",
    "def calc_fbeta(label_gt, label_pred):\n",
    "    assert label_gt.shape == label_pred.shape, f'mask.shape:{label_gt.shape} != mask_pred.shape:{label_pred.shape}'\n",
    "    label_gt = label_gt.astype(int).flatten()\n",
    "    label_pred = label_pred.flatten()\n",
    "\n",
    "    best_th = 0\n",
    "    best_dice = 0\n",
    "    # for th in np.array(range(10, 50 + 1, 5)) / 100:\n",
    "    for th in np.linspace(10, 91, 9) / 100:\n",
    "        # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n",
    "        # print(label_pred.max())\n",
    "        dice = fbeta_numpy(label_gt, (label_pred >= th).astype(int), beta=0.5)\n",
    "        # Logger.info(f'th: {th}, fbeta: {dice}')\n",
    "\n",
    "        if dice > best_dice:\n",
    "            best_dice = dice\n",
    "            best_th = th\n",
    "\n",
    "    # CTP,CFP, CTN, CFN\n",
    "    ctp = label_pred[label_gt == 1].sum()\n",
    "    cfp = label_pred[label_gt == 0].sum()\n",
    "    ctn = (1 - label_pred)[label_gt == 0].sum()\n",
    "    cfn = (1 - label_pred)[label_gt == 1].sum()\n",
    "    # logger as matrix\n",
    "    #Confused matrix\n",
    "    recall = ctp / (ctp + cfn)\n",
    "    precision = ctp / (ctp + cfp)\n",
    "    accuracy = (ctp + ctn) / (ctp + ctn + cfp + cfn)\n",
    "\n",
    "    con_mx = pd.DataFrame([[ctp, cfp], [cfn, ctn]], columns=['P', 'N'], index=['P', 'N'])\n",
    "\n",
    "    rates = pd.DataFrame([recall, precision, accuracy], index=['recall', 'precision', 'accuracy'], columns=[\"value\"])\n",
    "    Logger.info(f'Confusion matrix: \\n'\n",
    "                f'{con_mx} \\n'\n",
    "                f'Rates: \\n'\n",
    "                f'{rates}')\n",
    "\n",
    "    Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n",
    "    return best_dice, best_th\n",
    "\n",
    "\n",
    "def calc_cv(mask_gt, mask_pred):\n",
    "    best_dice, best_th = calc_fbeta(mask_gt, mask_pred)\n",
    "\n",
    "    return best_dice, best_th"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.300499Z",
     "end_time": "2023-04-24T20:21:21.300522Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LOSS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DiceLoss = smp.losses.DiceLoss(mode='binary')\n",
    "BCELoss = smp.losses.SoftBCEWithLogitsLoss()\n",
    "\n",
    "alpha = 0.5\n",
    "beta = 1 - alpha\n",
    "TverskyLoss = smp.losses.TverskyLoss(\n",
    "    mode='binary', log_loss=False, alpha=alpha, beta=beta)\n",
    "\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)\n",
    "    return BCELoss(y_pred, y_true)\n",
    "    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * TverskyLoss(y_pred, y_true)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:21:21.302230Z",
     "end_time": "2023-04-24T20:21:21.302308Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    # if imported wandb, use wandb.log\n",
    "    #\n",
    "\n",
    "    def __init__(self, mode=\"train\"):\n",
    "        self.val = None\n",
    "        self.avg = None\n",
    "        self.sum = None\n",
    "        self.count = None\n",
    "        self.mode = mode\n",
    "\n",
    "        self.reset()\n",
    "        # self.use_wandb = (importlib.util.find_spec('wandb') is not None)\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train and valid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    scaler = GradScaler(enabled=CONFIG[\"use_amp\"])\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    with tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
    "        for step, data in pbar:\n",
    "            images, masks, labels, positions = data\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with autocast(CONFIG[\"use_amp\"]):\n",
    "                y_preds = model(images).squeeze()\n",
    "                labels = labels.squeeze()\n",
    "\n",
    "                loss = criterion(y_preds, labels)\n",
    "\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), CONFIG[\"max_grad_norm\"])\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device, valid_mask_gt):\n",
    "    label_pred = np.zeros(valid_mask_gt.shape)\n",
    "    label_count = np.zeros(valid_mask_gt.shape)\n",
    "\n",
    "    model.eval()\n",
    "    losses = AverageMeter(mode='valid')\n",
    "\n",
    "    with tqdm(enumerate(valid_loader), total=len(valid_loader)) as pbar:\n",
    "        for step, (images, masks, labels, positions) in pbar:\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images).squeeze()\n",
    "                labels = labels.squeeze()\n",
    "                loss = criterion(y_preds, labels)\n",
    "            losses.update(loss.item(), batch_size)\n",
    "\n",
    "            # make whole mask\n",
    "            y_preds = torch.sigmoid(y_preds).to('cpu').numpy()\n",
    "            # start_idx = step*CONFIG[\"valid_batch_size\"]             # end_idx = start_idx + batch_size\n",
    "            # print(positions)\n",
    "            for i, (x1, y1, x2, y2) in enumerate(zip(*positions)):\n",
    "                label_pred[y1:y2, x1:x2] += y_preds[i]\n",
    "                label_count[y1:y2, x1:x2] += np.ones((y2 - y1, x2 - x1))\n",
    "\n",
    "    Logger.info(f'mask_count_min: {label_count.min()}')\n",
    "    label_pred /= label_count + 1e-8\n",
    "    return losses.avg, label_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:20:15.304646Z",
     "end_time": "2023-04-24T20:20:15.304767Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_fn(test_img, model, device, mask_gt, tile_size=224):\n",
    "    assert test_img.shape[1, 2] == mask_gt.shape[0, 1]\n",
    "    model.eval()\n",
    "    label_pred = np.zeros(mask_gt.shape)\n",
    "    label_count = np.zeros(mask_gt.shape)\n",
    "\n",
    "    ori_x, ori_y = mask_gt.shape()\n",
    "    if mask_gt.max() > 1:\n",
    "        mask_gt = mask_gt / 255\n",
    "\n",
    "    pad0 = (tile_size - ori_x % tile_size) % tile_size\n",
    "    pad1 = (tile_size - ori_y % tile_size) % tile_size\n",
    "    tiled_img = np.pad(test_img, [[0, 0], [0, pad0], [0, pad1]], constant_values=0)\n",
    "    tiled_mask = np.pad(mask_gt, [[0, 0], [0, pad0], [0, pad1]], constant_values=0)\n",
    "\n",
    "    nx = (ori_x + pad0) // tile_size\n",
    "    ny = (ori_y + pad1) // tile_size\n",
    "\n",
    "    for x, y in itertools.product(range(nx), range(ny)):\n",
    "        x1 = int(x * tile_size)\n",
    "        x2 = int(x * tile_size + tile_size)\n",
    "        y1 = int(y * tile_size)\n",
    "        y2 = int(y * tile_size + tile_size)\n",
    "\n",
    "        img = tiled_img[:, x1:x2, y1:y2]\n",
    "\n",
    "        img = img.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(img).squeeze()\n",
    "\n",
    "        label_pred[x1:x2, y1:y2] += y_preds>model.th)\n",
    "        label_count[x1:x2, y1:y2] += np.ones((tile_size, tile_size))\n",
    "\n",
    "    label_pred /= label_count + 1e-8\n",
    "    label_pred *= mask_gt\n",
    "\n",
    "    return label_pred[:ori_x, :ori_y]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EarlyStopping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = None\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score,val_loss, model):\n",
    "\n",
    "\n",
    "\n",
    "        if self.best_score is None:\n",
    "\n",
    "            self.save_checkpoint(score,val_loss, model)\n",
    "            return\n",
    "\n",
    "        if score > self.best_score + self.delta:\n",
    "            self.save_checkpoint(score,val_loss, model)\n",
    "            self.counter = 0\n",
    "            return\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            Logger.info(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, score ,val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            # Logger.info(\n",
    "            #     f\"Validation loss decreased ({self.val_loss_min:.6f} --> {score:.6f}).  Saving model ...\"\n",
    "            # )\n",
    "             Logger.info(\n",
    "                f\"Validation score increased ({self.best_score:.6f} --> {score:.6f}).  Saving model ...\")\n",
    "        save_path = get_saved_model_path(cfg)\n",
    "        if os.path.exists(save_path):\n",
    "            shutil.move(save_path, save_path.replace('.pt', '-bkp.pt'))\n",
    "        self.val_loss_min= val_loss\n",
    "        torch.save(\n",
    "            {\"model\": model.state_dict(),\n",
    "             \"best_score\": score,\n",
    "             \"best_loss\": val_loss,\n",
    "             \"th\": model.th\n",
    "             }\n",
    "            , save_path)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_foldset():\n",
    "    foldset = []\n",
    "    foldset.append({\n",
    "        'train': [1, 2],\n",
    "        'valid': [3]\n",
    "    })\n",
    "    foldset.append({\n",
    "        'train': [1, 3],\n",
    "        'valid': [2]\n",
    "    })\n",
    "    foldset.append({\n",
    "        'train': [2, 3],\n",
    "        'valid': [1]\n",
    "    })\n",
    "    return foldset\n",
    "\n",
    "\n",
    "def get_best_score(metric_direction):\n",
    "    if metric_direction == 'minimize':\n",
    "        return np.inf\n",
    "    elif metric_direction == 'maximize':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def should_update_best_score(metric_direction, score, best_score):\n",
    "    if metric_direction == 'minimize':\n",
    "        return score < best_score\n",
    "    elif metric_direction == 'maximize':\n",
    "        return score > best_score\n",
    "\n",
    "\n",
    "def preprocess_valid_mask_gt(valid_mask_gt, tile_size):\n",
    "    if valid_mask_gt.max() > 1:\n",
    "        Logger.info(f'valid_mask_gt.shape: {valid_mask_gt.shape} \\n'\n",
    "                    f'valid_mask_gt.max: {valid_mask_gt.max()} \\n')\n",
    "        valid_mask_gt = valid_mask_gt / 255\n",
    "\n",
    "    pad0 = (tile_size - valid_mask_gt.shape[0] % tile_size)\n",
    "    pad1 = (tile_size - valid_mask_gt.shape[1] % tile_size)\n",
    "    valid_mask_gt = np.pad(valid_mask_gt, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "\n",
    "    return valid_mask_gt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#    fold_configs = create_foldset()\n",
    "Logger.info(CONFIG)\n",
    "\n",
    "model, best_loss = build_model(cfg)\n",
    "best_loss = best_loss if best_loss is not None else np.inf\n",
    "model.to(device)\n",
    "\n",
    "if is_test:\n",
    "    pass\n",
    "\n",
    "if is_train:\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=Config.PATIENCE, verbose=True\n",
    "    )\n",
    "    fold_configs = create_foldset()\n",
    "    for epoch in range(CONFIG[\"epochs\"]//len(fold_configs)):\n",
    "        optimizer = AdamW(model.parameters(), lr=CONFIG[\"lr\"])\n",
    "        scheduler = get_scheduler(CONFIG, optimizer)\n",
    "\n",
    "        for fold_config in fold_configs:\n",
    "            train_loader = make_dataset(fold_config[\"train\"], dataset_mode='train')\n",
    "            valid_loader = make_dataset(fold_config[\"valid\"], dataset_mode='valid')\n",
    "\n",
    "            valid_mask_gt = valid_loader.dataset.get_gt(0)\n",
    "\n",
    "            valid_mask_gt = preprocess_valid_mask_gt(valid_mask_gt, CONFIG[\"tile_size\"])\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # train\n",
    "            avg_loss = train_fn(train_loader, model, criterion, optimizer, device)\n",
    "\n",
    "            # eval\n",
    "            avg_val_loss, label_pred = valid_fn(\n",
    "                valid_loader, model, criterion, device, valid_mask_gt)\n",
    "\n",
    "            scheduler_step(scheduler, avg_val_loss, epoch)\n",
    "\n",
    "            best_dice, best_th = calc_cv(valid_mask_gt, label_pred)\n",
    "\n",
    "            model.th = best_th\n",
    "\n",
    "            # score = avg_val_loss\n",
    "            score = best_dice\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "\n",
    "            early_stopping(score,avg_val_loss, model)\n",
    "\n",
    "            Logger.info(\n",
    "                f'Epoch {epoch + 1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "            Logger.info(\n",
    "                f'Epoch {epoch + 1} - avgScore: {score:.4f}')\n",
    "            if USE_WANDB:\n",
    "                wandb.log({\n",
    "                    \"train_loss\": avg_loss,\n",
    "                    \"val_loss\": avg_val_loss,\n",
    "                    \"best_dice\": best_dice,\n",
    "                    \"best_th\": best_th,\n",
    "                    \"best_loss\": best_loss,\n",
    "                })\n",
    "            if early_stopping.early_stop:\n",
    "                Logger.info(\"Early stopping\")\n",
    "                break\n",
    "        if early_stopping.early_stop:\n",
    "            Logger.info(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "\n",
    "del model, optimizer, scheduler, early_stopping, train_loader, valid_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "results = []\n",
    "for id in ['a', 'b']:\n",
    "\n",
    "    test_img=ImgLoader.load_from_path_static(\n",
    "        cache_dir=cfg['cache_dir'],\n",
    "        data_dir=cfg['data_dir'],\n",
    "        file_path=f\"test/{id}/surface_volume\",\n",
    "    )\n",
    "\n",
    "    mask=ImgLoader.load_from_path_static(\n",
    "        cache_dir=cfg['cache_dir'],\n",
    "        data_dir=cfg['data_dir'],\n",
    "        file_path=f\"test/{id}/mask.png\",\n",
    "    )\n",
    "    model, best_loss = build_model(cfg)\n",
    "    label_pred=test_fn(test_img, model, device,mask, cfg['tile_size'])\n",
    "\n",
    "    fig,ax= plt.subplots(1,3,figsize=(10,5))\n",
    "    ax[0].imshow(test_img)\n",
    "    ax[1].imshow(label_pred)\n",
    "    ax[2].imshow(mask)\n",
    "    ax[0].set_title('test_img')\n",
    "    ax[1].set_title('label_pred')\n",
    "    ax[2].set_title('mask')\n",
    "\n",
    "    plt.show()\n",
    "    results.append(label_pred)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
