{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2655.25813,
   "end_time": "2023-03-19T05:39:05.069796",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-19T04:54:49.811666",
   "version": "2.4.0"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This is my first time participating in a segmentation task competition.\n",
    "Please point out any problems with my code in the comments, as I want to make my code better.\n",
    "Also, please feel free to ask me any questions you may have.\n",
    "\n",
    "\n",
    "My code is to divide a 65 channel image into several 512*512 blocks and infer block by block.\n",
    "I don't want to train on blocks that have all 0 mask values."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.008212,
     "end_time": "2023-03-19T04:54:58.828996",
     "exception": false,
     "start_time": "2023-03-19T04:54:58.820784",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import socket\n",
    "import sys\n",
    "import time\n",
    "# try to edit locally and sync to kaggle\n",
    "\n",
    "is_kaggle = _dh == [\"/kaggle/working\"]\n",
    "is_train = True\n",
    "is_test = True\n",
    "\n",
    "\n",
    "NB = \"exp06\"\n",
    "HOST = socket.gethostname()\n",
    "date_time= time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "NB= NB + \"_\" + date_time\n",
    "NB, HOST, is_kaggle"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.023921,
     "end_time": "2023-03-19T04:54:58.859730",
     "exception": false,
     "start_time": "2023-03-19T04:54:58.835809",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:50:23.531705Z",
     "iopub.execute_input": "2023-04-02T01:50:23.532655Z",
     "iopub.status.idle": "2023-04-02T01:50:23.541871Z",
     "shell.execute_reply.started": "2023-04-02T01:50:23.532601Z",
     "shell.execute_reply": "2023-04-02T01:50:23.540824Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "('exp06_20230405_232331', 'Vincit', False)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "papermill": {
     "duration": 0.006611,
     "end_time": "2023-03-19T04:54:58.873056",
     "exception": false,
     "start_time": "2023-03-19T04:54:58.866445",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T11:12:28.789479Z",
     "iopub.execute_input": "2023-04-02T11:12:28.790355Z",
     "iopub.status.idle": "2023-04-02T11:12:28.832748Z",
     "shell.execute_reply.started": "2023-04-02T11:12:28.790304Z",
     "shell.execute_reply": "2023-04-02T11:12:28.831469Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# !nvidia-smi"
   ],
   "metadata": {
    "papermill": {
     "duration": 1.088018,
     "end_time": "2023-03-19T04:54:59.967896",
     "exception": false,
     "start_time": "2023-03-19T04:54:58.879878",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:50:23.543948Z",
     "iopub.execute_input": "2023-04-02T01:50:23.544964Z",
     "iopub.status.idle": "2023-04-02T01:50:24.576108Z",
     "shell.execute_reply.started": "2023-04-02T01:50:23.544922Z",
     "shell.execute_reply": "2023-04-02T01:50:24.574500Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as albu\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "logger=logging.getLogger(\"main\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import KFold, StratifiedGroupKFold, StratifiedKFold\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "if not is_kaggle:\n",
    "    ROOT_DIR = Path(\"../\")\n",
    "    DATA_DIR = ROOT_DIR / \"data\" / \"raw\"\n",
    "    OUTPUT_DIR = ROOT_DIR / \"saved\"\n",
    "    CP_DIR = OUTPUT_DIR / \"checkpoints\"\n",
    "    LOG_DIR = ROOT_DIR / \"saved\" / \"logs\"\n",
    "    CACHE_DIR = ROOT_DIR / \"saved\" / \"cache\"\n",
    "else:\n",
    "    ROOT_DIR = Path(\"/kaggle\")\n",
    "    DATA_DIR = ROOT_DIR / \"/input/vesuvius-challenge-ink-detection\"\n",
    "    OUTPUT_DIR = ROOT_DIR / \"working\"\n",
    "    CP_DIR = OUTPUT_DIR / \"ink-model\"\n",
    "    LOG_DIR = OUTPUT_DIR / \"saved\" / \"logs\"\n",
    "    CACHE_DIR = OUTPUT_DIR / \"saved\" / \"cache\"\n",
    "\n",
    "for p in [ROOT_DIR, DATA_DIR, OUTPUT_DIR, CP_DIR, LOG_DIR, CACHE_DIR]:\n",
    "    if os.path.exists(p) is False:\n",
    "        os.makedirs(p)\n",
    "\n",
    "if not is_kaggle:\n",
    "    from logzero import logger\n",
    "    import logzero\n",
    "    logzero.logfile(LOG_DIR / f\"{NB}.log\", maxBytes=1e8, backupCount=3)\n",
    "    logger.info(f\"NB: {NB}\")\n",
    "\n",
    "\n",
    "def to_pickle(filename, obj):\n",
    "    with open(filename, mode=\"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def unpickle(filename):\n",
    "    with open(filename, mode=\"rb\") as fo:\n",
    "        _ = pickle.load(fo)\n",
    "    return _"
   ],
   "metadata": {
    "papermill": {
     "duration": 5.464665,
     "end_time": "2023-03-19T04:55:05.444343",
     "exception": false,
     "start_time": "2023-03-19T04:54:59.979678",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:50:24.578567Z",
     "iopub.execute_input": "2023-04-02T01:50:24.579389Z",
     "iopub.status.idle": "2023-04-02T01:50:24.595301Z",
     "shell.execute_reply.started": "2023-04-02T01:50:24.579335Z",
     "shell.execute_reply": "2023-04-02T01:50:24.594244Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 230405 23:23:36 390853298:57] NB: exp06_20230405_232331\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "papermill": {
     "duration": 0.006639,
     "end_time": "2023-03-19T04:55:05.458204",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.451565",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "papermill": {
     "duration": 0.006549,
     "end_time": "2023-03-19T04:55:05.471535",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.464986",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import multiprocessing\n",
    "\n",
    "print(\"cpu count:\", multiprocessing.cpu_count())\n",
    "\n",
    "\n",
    "class Config:\n",
    "    N_FOLD = 5\n",
    "    RANDOM_SATE = 42\n",
    "    LR = 1.0e-05\n",
    "    MAX_LR = 1.0e-5\n",
    "    PATIENCE = 15\n",
    "    EPOCH = 8\n",
    "    BATCH_SIZE = 8\n",
    "    IMG_SIZE = 128\n",
    "    NUM_WORKERS = multiprocessing.cpu_count()\n",
    "    \n",
    "\n",
    "SCAN_SLICE = 65\n",
    "SAMPLE_GAP = 3\n",
    "SAMPLE_SIZE= len(range(0, SCAN_SLICE, SAMPLE_GAP))\n",
    "\n",
    "\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(seed=Config.RANDOM_SATE)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.021519,
     "end_time": "2023-03-19T04:55:05.500022",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.478503",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:50:24.598648Z",
     "iopub.execute_input": "2023-04-02T01:50:24.599772Z",
     "iopub.status.idle": "2023-04-02T01:50:24.611388Z",
     "shell.execute_reply.started": "2023-04-02T01:50:24.599732Z",
     "shell.execute_reply": "2023-04-02T01:50:24.610229Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu count: 16\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "glob.glob(str(DATA_DIR / \"*\"))"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.019617,
     "end_time": "2023-03-19T04:55:05.526384",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.506767",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:50:24.613107Z",
     "iopub.execute_input": "2023-04-02T01:50:24.613920Z",
     "iopub.status.idle": "2023-04-02T01:50:24.625428Z",
     "shell.execute_reply.started": "2023-04-02T01:50:24.613883Z",
     "shell.execute_reply": "2023-04-02T01:50:24.624228Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['..\\\\data\\\\raw\\\\sample_submission.csv',\n '..\\\\data\\\\raw\\\\test',\n '..\\\\data\\\\raw\\\\train']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def rle(img,thr):\n",
    "    flat_img = np.where(img.flatten() > thr, 1, 0).astype(np.uint8)\n",
    "\n",
    "    starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n",
    "    ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n",
    "    starts_ix = np.where(starts)[0] + 2\n",
    "    ends_ix = np.where(ends)[0] + 2\n",
    "    lengths = ends_ix - starts_ix\n",
    "    return starts_ix, lengths\n",
    "\n",
    "def concat_tile(im_list_2d):\n",
    "    return cv2.vconcat([cv2.hconcat(im_list_h) for im_list_h in im_list_2d])"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.017333,
     "end_time": "2023-03-19T04:55:05.550539",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.533206",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:50:24.627282Z",
     "iopub.execute_input": "2023-04-02T01:50:24.627927Z",
     "iopub.status.idle": "2023-04-02T01:50:24.636534Z",
     "shell.execute_reply.started": "2023-04-02T01:50:24.627892Z",
     "shell.execute_reply": "2023-04-02T01:50:24.635456Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "papermill": {
     "duration": 0.006691,
     "end_time": "2023-03-19T04:55:05.564600",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.557909",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# define of classes"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.00681,
     "end_time": "2023-03-19T04:55:05.633687",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.626877",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_augmentation():\n",
    "    train_transform = [\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.5),\n",
    "        albu.Resize(height=Config.IMG_SIZE, width=Config.IMG_SIZE),\n",
    "        albu.Normalize(mean=[0], std=[1]),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_test_augmentation():\n",
    "    train_transform = [\n",
    "        albu.Resize(height=Config.IMG_SIZE, width=Config.IMG_SIZE),\n",
    "        albu.Normalize(mean=[0], std=[1]),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.016236,
     "end_time": "2023-03-19T04:55:05.656750",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.640514",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:53:06.315388Z",
     "iopub.execute_input": "2023-04-02T01:53:06.315763Z",
     "iopub.status.idle": "2023-04-02T01:53:06.324878Z",
     "shell.execute_reply.started": "2023-04-02T01:53:06.315724Z",
     "shell.execute_reply": "2023-04-02T01:53:06.323864Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "papermill": {
     "duration": 0.026966,
     "end_time": "2023-03-19T04:55:05.690754",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.663788",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:53:06.329050Z",
     "iopub.execute_input": "2023-04-02T01:53:06.329332Z",
     "iopub.status.idle": "2023-04-02T01:53:06.348617Z",
     "shell.execute_reply.started": "2023-04-02T01:53:06.329306Z",
     "shell.execute_reply": "2023-04-02T01:53:06.347681Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if not is_kaggle:\n",
    "    from CVDataSet import CVDataSet\n",
    "else:\n",
    "    class CVDataSet(Dataset):\n",
    "        def __init__(self, imgs, transforms, labels=None, data_type=None, crop_size=256):\n",
    "            self.crop_size = crop_size\n",
    "            self.imgs = imgs\n",
    "            self.transforms = transforms\n",
    "            self.labels = labels\n",
    "            self.data_type = data_type\n",
    "\n",
    "            self.cell_counts = []\n",
    "            for img in self.imgs:\n",
    "                cell_count = math.ceil(img.shape[1] / self.crop_size) * math.ceil(\n",
    "                    img.shape[2] / self.crop_size\n",
    "                )\n",
    "                self.cell_counts.append(cell_count)\n",
    "\n",
    "        def __len__(self):\n",
    "            data_count = 0\n",
    "            if self.data_type == \"train\":\n",
    "\n",
    "                self.cell_id_maps = {}\n",
    "\n",
    "                counter = 0\n",
    "                for img_num, img in enumerate(self.imgs):\n",
    "\n",
    "                    cell_count = math.ceil(img.shape[1] / self.crop_size) * math.ceil(\n",
    "                        img.shape[2] / self.crop_size\n",
    "                    )\n",
    "                    for cell_id in range(cell_count):\n",
    "                        h_num = cell_id // math.ceil(\n",
    "                            self.labels[img_num].shape[1] / self.crop_size\n",
    "                        )\n",
    "                        w_num = cell_id - (\n",
    "                                h_num\n",
    "                                * math.ceil(self.labels[img_num].shape[1] / self.crop_size)\n",
    "                        )\n",
    "\n",
    "                        cropped_img = self.labels[img_num][\n",
    "                                      h_num * self.crop_size: h_num * self.crop_size\n",
    "                                                              + self.crop_size,\n",
    "                                      w_num * self.crop_size: w_num * self.crop_size\n",
    "                                                              + self.crop_size,\n",
    "                                      ]\n",
    "\n",
    "                        if cropped_img.sum() == 0:\n",
    "                            continue\n",
    "\n",
    "                        data_count += 1\n",
    "\n",
    "                        self.cell_id_maps[counter] = (img_num, cell_id)\n",
    "                        counter += 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                for img in self.imgs:\n",
    "                    data_count += math.ceil(img.shape[1] / self.crop_size) * math.ceil(\n",
    "                        img.shape[2] / self.crop_size\n",
    "                    )\n",
    "            return data_count\n",
    "\n",
    "        def calc_img_num(self, idx):\n",
    "            cum_cell_count = 0\n",
    "            for i, cell_count in enumerate(self.cell_counts):\n",
    "                cum_cell_count += cell_count\n",
    "                if idx + 1 <= cum_cell_count:\n",
    "                    return i, idx - (cum_cell_count - cell_count)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "\n",
    "            if self.data_type == \"train\":\n",
    "                img_num, cell_id = self.cell_id_maps[idx]\n",
    "            else:\n",
    "                img_num, cell_id = self.calc_img_num(idx)\n",
    "\n",
    "            target_img = self.imgs[img_num]\n",
    "            # if self.data_type != \"test\":\n",
    "            if self.data_type in [\"train\", \"valid\"]:\n",
    "                target_label = self.labels[img_num]\n",
    "\n",
    "            # print(target_label.shape)\n",
    "            target_img = np.moveaxis(target_img, 0, 2)\n",
    "            # target_label = np.moveaxis(target_label, 0, 2)\n",
    "\n",
    "            h_num = cell_id // math.ceil(target_img.shape[1] / self.crop_size)\n",
    "            w_num = cell_id - (h_num * math.ceil(target_img.shape[1] / self.crop_size))\n",
    "\n",
    "            cropped_img = target_img[\n",
    "                          h_num * self.crop_size: h_num * self.crop_size + self.crop_size,\n",
    "                          w_num * self.crop_size: w_num * self.crop_size + self.crop_size,\n",
    "                          ]\n",
    "\n",
    "            if self.data_type in [\"train\", \"valid\"]:\n",
    "                cropped_label = target_label[\n",
    "                                h_num * self.crop_size: h_num * self.crop_size + self.crop_size,\n",
    "                                w_num * self.crop_size: w_num * self.crop_size + self.crop_size,\n",
    "                                ]\n",
    "                augmented = self.transforms(image=cropped_img, mask=cropped_label)\n",
    "                img = augmented[\"image\"]\n",
    "                img = np.moveaxis(img, 2, 0)\n",
    "                mask = augmented[\"mask\"]\n",
    "            else:\n",
    "                augmented = self.transforms(image=cropped_img)\n",
    "                img = augmented[\"image\"]\n",
    "                img = np.moveaxis(img, 2, 0)\n",
    "                mask = -1\n",
    "\n",
    "            return img, mask / 255"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.006722,
     "end_time": "2023-03-19T04:55:05.704358",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.697636",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if not is_kaggle:\n",
    "    from CVNet import CVNet\n",
    "else:\n",
    "    class CVNet(nn.Module):\n",
    "        def __init__(self, num_classes):\n",
    "            super(CVNet, self).__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.contracting_11 = self.conv_block(in_channels=SAMPLE_SIZE, out_channels=64)\n",
    "            self.contracting_12 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.contracting_21 = self.conv_block(in_channels=64, out_channels=128)\n",
    "            self.contracting_22 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.contracting_31 = self.conv_block(in_channels=128, out_channels=256)\n",
    "            self.contracting_32 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.contracting_41 = self.conv_block(in_channels=256, out_channels=512)\n",
    "            self.contracting_42 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.middle = self.conv_block(in_channels=512, out_channels=1024)\n",
    "            self.expansive_11 = nn.ConvTranspose2d(\n",
    "                in_channels=1024,\n",
    "                out_channels=512,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1,\n",
    "            )\n",
    "            self.expansive_12 = self.conv_block(in_channels=1024, out_channels=512)\n",
    "            self.expansive_21 = nn.ConvTranspose2d(\n",
    "                in_channels=512,\n",
    "                out_channels=256,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1,\n",
    "            )\n",
    "            self.expansive_22 = self.conv_block(in_channels=512, out_channels=256)\n",
    "            self.expansive_31 = nn.ConvTranspose2d(\n",
    "                in_channels=256,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1,\n",
    "            )\n",
    "            self.expansive_32 = self.conv_block(in_channels=256, out_channels=128)\n",
    "            self.expansive_41 = nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1,\n",
    "            )\n",
    "            self.expansive_42 = self.conv_block(in_channels=128, out_channels=64)\n",
    "            self.output = nn.Conv2d(\n",
    "                in_channels=64, out_channels=num_classes, kernel_size=3, stride=1, padding=1\n",
    "            )\n",
    "\n",
    "        @staticmethod\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1,\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(num_features=out_channels),\n",
    "                nn.Conv2d(\n",
    "                    in_channels=out_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1,\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(num_features=out_channels),\n",
    "            )\n",
    "            return block\n",
    "\n",
    "        def forward(self, X):\n",
    "            contracting_11_out = self.contracting_11(X)  # [-1, 64, 256, 256]\n",
    "            contracting_12_out = self.contracting_12(\n",
    "                contracting_11_out\n",
    "            )  # [-1, 64, 128, 128]\n",
    "            contracting_21_out = self.contracting_21(\n",
    "                contracting_12_out\n",
    "            )  # [-1, 128, 128, 128]\n",
    "            contracting_22_out = self.contracting_22(\n",
    "                contracting_21_out\n",
    "            )  # [-1, 128, 64, 64]\n",
    "            contracting_31_out = self.contracting_31(\n",
    "                contracting_22_out\n",
    "            )  # [-1, 256, 64, 64]\n",
    "            contracting_32_out = self.contracting_32(\n",
    "                contracting_31_out\n",
    "            )  # [-1, 256, 32, 32]\n",
    "            contracting_41_out = self.contracting_41(\n",
    "                contracting_32_out\n",
    "            )  # [-1, 512, 32, 32]\n",
    "            contracting_42_out = self.contracting_42(\n",
    "                contracting_41_out\n",
    "            )  # [-1, 512, 16, 16]\n",
    "            middle_out = self.middle(contracting_42_out)  # [-1, 1024, 16, 16]\n",
    "            expansive_11_out = self.expansive_11(middle_out)  # [-1, 512, 32, 32]\n",
    "            expansive_12_out = self.expansive_12(\n",
    "                torch.cat((expansive_11_out, contracting_41_out), dim=1)\n",
    "            )  # [-1, 1024, 32, 32] -> [-1, 512, 32, 32]\n",
    "            expansive_21_out = self.expansive_21(expansive_12_out)  # [-1, 256, 64, 64]\n",
    "            expansive_22_out = self.expansive_22(\n",
    "                torch.cat((expansive_21_out, contracting_31_out), dim=1)\n",
    "            )  # [-1, 512, 64, 64] -> [-1, 256, 64, 64]\n",
    "            expansive_31_out = self.expansive_31(expansive_22_out)  # [-1, 128, 128, 128]\n",
    "            expansive_32_out = self.expansive_32(\n",
    "                torch.cat((expansive_31_out, contracting_21_out), dim=1)\n",
    "            )  # [-1, 256, 128, 128] -> [-1, 128, 128, 128]\n",
    "            expansive_41_out = self.expansive_41(expansive_32_out)  # [-1, 64, 256, 256]\n",
    "            expansive_42_out = self.expansive_42(\n",
    "                torch.cat((expansive_41_out, contracting_11_out), dim=1)\n",
    "            )  # [-1, 128, 256, 256] -> [-1, 64, 256, 256]\n",
    "            output_out = self.output(expansive_42_out)  # [-1, num_classes, 256, 256]\n",
    "            return output_out\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.02715,
     "end_time": "2023-03-19T04:55:05.738302",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.711152",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:53:06.350283Z",
     "iopub.execute_input": "2023-04-02T01:53:06.350647Z",
     "iopub.status.idle": "2023-04-02T01:53:06.371653Z",
     "shell.execute_reply.started": "2023-04-02T01:53:06.350608Z",
     "shell.execute_reply": "2023-04-02T01:53:06.370679Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, fold=\"\"):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            logger.info(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            logger.info(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "            )\n",
    "\n",
    "        # if os.path.exists(CP_DIR / f'checkpoint_{NB}_{fold}.pt'):\n",
    "        #    shutil.move(CP_DIR / f'checkpoint_{NB}_{fold}.pt', CP_DIR / f'checkpoint_{NB}_{fold}-2.pt')\n",
    "        torch.save(model.state_dict(), CP_DIR / f\"{HOST}_{NB}_checkpoint_{fold}.pt\")\n",
    "        self.val_loss_min = val_loss"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.018979,
     "end_time": "2023-03-19T04:55:05.764174",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.745195",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:53:06.374655Z",
     "iopub.execute_input": "2023-04-02T01:53:06.375070Z",
     "iopub.status.idle": "2023-04-02T01:53:06.386253Z",
     "shell.execute_reply.started": "2023-04-02T01:53:06.375043Z",
     "shell.execute_reply": "2023-04-02T01:53:06.385257Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.070809,
     "end_time": "2023-03-19T04:55:05.841942",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.771133",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:53:06.387941Z",
     "iopub.execute_input": "2023-04-02T01:53:06.388320Z",
     "iopub.status.idle": "2023-04-02T01:53:06.406830Z",
     "shell.execute_reply.started": "2023-04-02T01:53:06.388284Z",
     "shell.execute_reply": "2023-04-02T01:53:06.405836Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 25.20it/s]\n",
      "100%|██████████| 22/22 [00:02<00:00,  8.87it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 32.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_img(file_path: str):\n",
    "    # if cached data exists, load it\n",
    "    path__npy_ = CACHE_DIR / f\"{file_path}.npy\"\n",
    "    if os.path.exists(path__npy_):\n",
    "        return np.load(path__npy_)\n",
    "    else:\n",
    "        img_l = cv2.imread(str(DATA_DIR / file_path), 0)\n",
    "        if not os.path.exists(path__npy_.parent):\n",
    "            os.makedirs(path__npy_.parent)\n",
    "        np.save(path__npy_, img_l)\n",
    "        return img_l\n",
    "\n",
    "if is_train:\n",
    "\n",
    "\n",
    "    img1 = []\n",
    "    img2 = []\n",
    "    img3 = []\n",
    "\n",
    "    _=[img1,img2,img3]\n",
    "\n",
    "    for k in range(1,4):\n",
    "        for i in tqdm(range(0,SCAN_SLICE,SAMPLE_GAP)):\n",
    "            img = load_img(f\"train/{k}/surface_volume/{i:02}.tif\")\n",
    "            eval(f\"img{k}\").append(img)\n",
    "        # eval(f'img{k} = np.stack(img{k})')\n",
    "        if k==1:\n",
    "            img1=np.stack(img1)\n",
    "        elif k==2:\n",
    "            img2=np.stack(img2)\n",
    "        elif k==3:\n",
    "            img3=np.stack(img3)\n",
    "\n",
    "    img1_label = load_img(f\"train/1/inklabels.png\")\n",
    "    img2_label = load_img(f\"train/2/inklabels.png\")\n",
    "    img3_label = load_img(f\"train/3/inklabels.png\")\n",
    "\n",
    "    img1_mask = load_img(f\"train/1/mask.png\")\n",
    "    img2_mask = load_img(f\"train/2/mask.png\")\n",
    "    img3_mask = load_img(f\"train/3/mask.png\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if is_train:\n",
    "    data_set = []\n",
    "\n",
    "    data_set.append(\n",
    "        {\n",
    "            \"train_img\": [img1, img2],\n",
    "            \"train_label\": [img1_label, img2_label],\n",
    "            \"valid_img\": [img3],\n",
    "            \"valid_label\": [img3_label],\n",
    "            \"valid_mask\": [img3_mask],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    data_set.append(\n",
    "        {\n",
    "            \"train_img\": [img1, img3],\n",
    "            \"train_label\": [img1_label, img3_label],\n",
    "            \"valid_img\": [img2],\n",
    "            \"valid_label\": [img2_label],\n",
    "            \"valid_mask\": [img2_mask],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    data_set.append(\n",
    "        {\n",
    "            \"train_img\": [img2, img3],\n",
    "            \"train_label\": [img2_label, img3_label],\n",
    "            \"valid_img\": [img1],\n",
    "            \"valid_label\": [img1_label],\n",
    "            \"valid_mask\": [img1_mask],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(time.strftime(time.strftime(\"%Y%m%d_%H%M%S\")))\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.017288,
     "end_time": "2023-03-19T04:55:05.866433",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.849145",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:53:06.408465Z",
     "iopub.execute_input": "2023-04-02T01:53:06.409428Z",
     "iopub.status.idle": "2023-04-02T01:53:06.417411Z",
     "shell.execute_reply.started": "2023-04-02T01:53:06.409390Z",
     "shell.execute_reply": "2023-04-02T01:53:06.416454Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230405_232341\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "if is_train:\n",
    "    for fold in range(0, 3):\n",
    "        print(f\"====== {fold} ======\")\n",
    "\n",
    "        net = CVNet(1,in_channel_size=SAMPLE_SIZE)\n",
    "        net.to(device)\n",
    "\n",
    "        # criterion = nn.MSELoss()\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = optim.AdamW(net.parameters(), lr=Config.LR, weight_decay=1.0e-02)\n",
    "\n",
    "        # train, valid = train_df.iloc[train_index], train_df.iloc[test_index]\n",
    "        # y_train, y_valid = train_labels.iloc[train_index], train_labels.iloc[test_index]\n",
    "\n",
    "        train_dataset = CVDataSet(\n",
    "            data_set[fold][\"train_img\"],\n",
    "            get_augmentation(),\n",
    "            labels=data_set[fold][\"train_label\"],\n",
    "            data_type=\"train\",\n",
    "            crop_size=Config.IMG_SIZE,\n",
    "            device=device,\n",
    "        )\n",
    "        valid_dataset = CVDataSet(\n",
    "            data_set[fold][\"valid_img\"],\n",
    "            get_augmentation(),\n",
    "            labels=data_set[fold][\"valid_label\"],\n",
    "            data_type=\"valid\",\n",
    "            crop_size=Config.IMG_SIZE,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        trainloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            pin_memory=True,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            num_workers=Config.NUM_WORKERS // 2,\n",
    "        )\n",
    "        validloader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            pin_memory=True,\n",
    "            num_workers=Config.NUM_WORKERS // 2,\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            patience=Config.PATIENCE, verbose=True, fold=fold\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            epochs=Config.EPOCH,\n",
    "            steps_per_epoch=len(trainloader),\n",
    "            max_lr=Config.MAX_LR,\n",
    "            pct_start=0.1,\n",
    "            anneal_strategy=\"cos\",\n",
    "            div_factor=1.0e3,\n",
    "            final_div_factor=1.0e3,\n",
    "        )\n",
    "\n",
    "        val_metrics = []\n",
    "        learning_rates = []\n",
    "\n",
    "        for epoch in range(Config.EPOCH):\n",
    "\n",
    "            running_loss = 0.0\n",
    "            train_rmse_list = []\n",
    "            n_iter = len(trainloader)\n",
    "            with tqdm(enumerate(trainloader), total=n_iter) as pbar:\n",
    "                for i, (img, target) in pbar:\n",
    "\n",
    "                    net.train()\n",
    "                    # zero the parameter gradients\n",
    "                    # optimizer.zero_grad()\n",
    "\n",
    "                    img, target = img.to(device).float(), target.to(device).float()\n",
    "\n",
    "                    outputs = net(img)\n",
    "\n",
    "                    loss = criterion(outputs.squeeze(), target)\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    net.zero_grad()\n",
    "\n",
    "                    # print statistics\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                    outputs_np = outputs.to(\"cpu\").detach().numpy().copy()\n",
    "\n",
    "                    pbar.set_postfix(\n",
    "                        OrderedDict(\n",
    "                            epoch=\"{:>10}\".format(epoch),\n",
    "                            loss=\"{:.4f}\".format(loss.item()),\n",
    "                        )\n",
    "                    )\n",
    "                    scheduler.step()\n",
    "\n",
    "            val_preds = []\n",
    "            valid_targets = []\n",
    "            n_iter_val = len(validloader)\n",
    "            for i, (img, target) in tqdm(\n",
    "                enumerate(validloader), total=n_iter_val, smoothing=0\n",
    "            ):\n",
    "                net.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    img, pawpularities = (\n",
    "                        img.to(device).float(),\n",
    "                        target.to(device).float(),\n",
    "                    )\n",
    "                    outputs = net(img)\n",
    "                    outputs = outputs.sigmoid()\n",
    "                    outputs_np = outputs.to(\"cpu\").detach().numpy().copy()\n",
    "\n",
    "                    val_preds.append(outputs_np)\n",
    "                    valid_targets.append(\n",
    "                        pawpularities.to(\"cpu\").detach().numpy().copy()\n",
    "                    )\n",
    "\n",
    "            ## 端を切る\n",
    "            w_count = math.ceil(\n",
    "                data_set[fold][\"valid_label\"][0].shape[1] / Config.IMG_SIZE\n",
    "            )\n",
    "            h_count = math.ceil(\n",
    "                data_set[fold][\"valid_label\"][0].shape[0] / Config.IMG_SIZE\n",
    "            )\n",
    "\n",
    "            tile_arry = []\n",
    "            stack_pred = np.vstack(val_preds).reshape(\n",
    "                -1, Config.IMG_SIZE, Config.IMG_SIZE\n",
    "            )\n",
    "            for h_i in range(h_count):\n",
    "                # print(len(test_preds[h_i * w_count:(h_i + 1) * w_count]), h_i * w_count, (h_i + 1) * w_count)\n",
    "                tile_arry.append(stack_pred[h_i * w_count : (h_i + 1) * w_count])\n",
    "\n",
    "            pred_tile_img = concat_tile(tile_arry)\n",
    "            pred_tile_img = np.where(\n",
    "                data_set[fold][\"valid_mask\"][0] > 1,\n",
    "                pred_tile_img[\n",
    "                    : data_set[fold][\"valid_label\"][0].shape[0],\n",
    "                    : data_set[fold][\"valid_label\"][0].shape[1],\n",
    "                ],\n",
    "                0,\n",
    "            )\n",
    "            auc = roc_auc_score(\n",
    "                data_set[fold][\"valid_label\"][0].reshape(-1),\n",
    "                pred_tile_img.reshape(-1),\n",
    "            )\n",
    "            auc\n",
    "\n",
    "            logger.info(\"auc:{:.4f}\".format(auc))\n",
    "\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            val_metrics.append(auc)\n",
    "            learning_rates.append(lr)\n",
    "\n",
    "            early_stopping(-auc, net)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                logger.info(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.plot(learning_rates)\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(val_metrics)\n",
    "        plt.show()\n",
    "        plt.legend([\"lr\", \"auc\"])\n",
    "\n",
    "        del net, validloader, trainloader, train_dataset, valid_dataset, img, target, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.027409,
     "end_time": "2023-03-19T04:55:05.900866",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.873457",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-04-02T01:53:06.418853Z",
     "iopub.execute_input": "2023-04-02T01:53:06.419438Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== 0 ======\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11412\\1681302082.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[0mtrain_rmse_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m             \u001B[0mn_iter\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrainloader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m             \u001B[1;32mwith\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrainloader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtotal\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_iter\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpbar\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m                 \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpbar\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\kaggle_Vesuvius\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    433\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterator\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    434\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 435\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    436\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    437\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\kaggle_Vesuvius\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    379\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    380\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcheck_worker_number_rationality\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 381\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0m_MultiProcessingDataLoaderIter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    382\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    383\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\kaggle_Vesuvius\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1032\u001B[0m             \u001B[1;31m#     before it starts, and __del__ tries to join but will get:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1033\u001B[0m             \u001B[1;31m#     AssertionError: can only join a started process.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1034\u001B[1;33m             \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1035\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_index_queues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex_queue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1036\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_workers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\kaggle_Vesuvius\\lib\\multiprocessing\\process.py\u001B[0m in \u001B[0;36mstart\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    110\u001B[0m                \u001B[1;34m'daemonic processes are not allowed to have children'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m         \u001B[0m_cleanup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 112\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    113\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sentinel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentinel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[1;31m# Avoid a refcycle if the target function holds an indirect\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\kaggle_Vesuvius\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    221\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 223\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mProcess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    224\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mDefaultContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\kaggle_Vesuvius\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    320\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    321\u001B[0m             \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mpopen_spawn_win32\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 322\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    323\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    324\u001B[0m     \u001B[1;32mclass\u001B[0m \u001B[0mSpawnContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\kaggle_Vesuvius\\lib\\multiprocessing\\popen_spawn_win32.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     87\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 89\u001B[1;33m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     90\u001B[0m             \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m                 \u001B[0mset_spawning_popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\kaggle_Vesuvius\\lib\\multiprocessing\\reduction.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m     \u001B[0mForkingPickler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: [Errno 22] Invalid argument"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "papermill": {
     "duration": 0.006877,
     "end_time": "2023-03-19T04:55:05.914721",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.907844",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.006809,
     "end_time": "2023-03-19T04:55:05.928511",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.921702",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "if is_train:\n",
    "    all_preds = []\n",
    "    all_masks = []\n",
    "    for fold in range(0, 3):\n",
    "        print(f\"====== {fold} ======\")\n",
    "\n",
    "        net = CVNet(1)\n",
    "        net.load_state_dict(torch.load(CP_DIR / f\"{HOST}_{NB}_checkpoint_{fold}.pt\"))\n",
    "        net.to(device)\n",
    "\n",
    "        valid_dataset = CVDataSet(\n",
    "            data_set[fold][\"valid_img\"],\n",
    "            get_augmentation(),\n",
    "            labels=data_set[fold][\"valid_label\"],\n",
    "            data_type=\"valid\",\n",
    "            crop_size=Config.IMG_SIZE,\n",
    "        )\n",
    "\n",
    "        validloader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=int(Config.BATCH_SIZE / 4),\n",
    "            pin_memory=True,\n",
    "            num_workers=Config.NUM_WORKERS - 2,\n",
    "        )\n",
    "\n",
    "        val_preds = []\n",
    "        valid_targets = []\n",
    "        n_iter_val = len(validloader)\n",
    "        for i, (img, target) in tqdm(enumerate(validloader), total=n_iter_val):\n",
    "            net.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                img, pawpularities = img.to(device).float(), target.to(device).float()\n",
    "                outputs = net(img)\n",
    "                outputs = outputs.sigmoid()\n",
    "                outputs_np = outputs.to(\"cpu\").detach().numpy().copy()\n",
    "\n",
    "                val_preds.append(outputs_np)\n",
    "                valid_targets.append(pawpularities.to(\"cpu\").detach().numpy().copy())\n",
    "\n",
    "        ## 端を切る\n",
    "        w_count = math.ceil(data_set[fold][\"valid_label\"][0].shape[1] / Config.IMG_SIZE)\n",
    "        h_count = math.ceil(data_set[fold][\"valid_label\"][0].shape[0] / Config.IMG_SIZE)\n",
    "\n",
    "        tile_arry = []\n",
    "        stack_pred = np.vstack(val_preds).reshape(-1, Config.IMG_SIZE, Config.IMG_SIZE)\n",
    "        for h_i in range(h_count):\n",
    "            # print(len(test_preds[h_i * w_count:(h_i + 1) * w_count]), h_i * w_count, (h_i + 1) * w_count)\n",
    "            tile_arry.append(stack_pred[h_i * w_count : (h_i + 1) * w_count])\n",
    "\n",
    "        pred_tile_img = concat_tile(tile_arry)\n",
    "        pred_tile_img = np.where(\n",
    "            data_set[fold][\"valid_mask\"][0] > 1,\n",
    "            pred_tile_img[\n",
    "                : data_set[fold][\"valid_label\"][0].shape[0],\n",
    "                : data_set[fold][\"valid_label\"][0].shape[1],\n",
    "            ],\n",
    "            0,\n",
    "        )\n",
    "\n",
    "        auc = roc_auc_score(\n",
    "            data_set[fold][\"valid_label\"][0].reshape(-1),\n",
    "            pred_tile_img.reshape(-1),\n",
    "        )\n",
    "        auc\n",
    "\n",
    "        all_masks.append(data_set[fold][\"valid_label\"][0].reshape(-1))\n",
    "        all_preds.append(pred_tile_img.reshape(-1))\n",
    "\n",
    "        print(auc)\n",
    "\n",
    "        del net, validloader, valid_dataset, img, target, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.022963,
     "end_time": "2023-03-19T04:55:05.958562",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.935599",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if is_train:\n",
    "    flat_preds = np.hstack(all_preds).reshape(-1).astype(float)\n",
    "    flat_masks = (np.hstack(all_masks).reshape(-1) / 255).astype(int)\n",
    "\n",
    "    plt.hist(flat_preds, bins=50)\n",
    "    plt.legend([\"pred\"])\n",
    "    plt.show()"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.01571,
     "end_time": "2023-03-19T04:55:05.981729",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.966019",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if is_train:\n",
    "    thr_list = []\n",
    "    for thr in tqdm(np.arange(0.2, 0.6, 0.1)):\n",
    "        _val_pred = np.where(flat_preds > thr, 1, 0).astype(int)\n",
    "        score = f1_score(flat_masks, _val_pred)\n",
    "        print(thr, score)\n",
    "        thr_list.append({\"thr\": thr, \"score\": score})"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.015705,
     "end_time": "2023-03-19T04:55:06.004524",
     "exception": false,
     "start_time": "2023-03-19T04:55:05.988819",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def predict(test_data_dir):\n",
    "    test_img = []\n",
    "    for i in tqdm(range(0,SCAN_SLICE,SAMPLE_GAP)):\n",
    "        test_img.append(\n",
    "            cv2.imread(str(test_data_dir / f\"surface_volume/{i:02}.tif\"), 0)\n",
    "        )\n",
    "\n",
    "    test_img = np.stack(test_img)\n",
    "    print(test_img.shape)\n",
    "\n",
    "    # mask\n",
    "    test_mask = cv2.imread(str(test_data_dir / \"mask.png\"), 0)\n",
    "\n",
    "    nets = []\n",
    "\n",
    "    for fold in range(3):\n",
    "        net = CVNet(1)\n",
    "        net.to(device)\n",
    "        net.load_state_dict(torch.load(CP_DIR / f\"{HOST}_{NB}_checkpoint_{fold}.pt\"))\n",
    "        nets.append(net)\n",
    "\n",
    "    test_dataset = CVDataSet(\n",
    "        [test_img], get_test_augmentation(), data_type=\"test\", crop_size=Config.IMG_SIZE\n",
    "    )\n",
    "\n",
    "    testloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=max(1,int(Config.BATCH_SIZE / 8)),\n",
    "        pin_memory=True,\n",
    "        num_workers=Config.NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "    val_metrics = []\n",
    "    learning_rates = []\n",
    "\n",
    "    # for epoch in range(Config.EPOCH):\n",
    "    for epoch in range(1):\n",
    "\n",
    "        test_preds = []\n",
    "        n_iter_val = len(testloader)\n",
    "        for i, (img, target) in tqdm(enumerate(testloader), total=n_iter_val):\n",
    "            net.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                img, pawpularities = img.to(device).float(), target.to(device).float()\n",
    "\n",
    "                outputs_all = np.zeros((img.shape[0], img.shape[2], img.shape[3]))\n",
    "\n",
    "                for net in nets:\n",
    "                    outputs = net(img)\n",
    "                    outputs = outputs.sigmoid()\n",
    "                    outputs_np = outputs.squeeze().to(\"cpu\").detach().numpy().copy()\n",
    "                    outputs_all += outputs_np / 3\n",
    "\n",
    "                test_preds.append(outputs_all)\n",
    "\n",
    "    del net, testloader, test_dataset\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    w_count = math.ceil(test_img[0].shape[1] / Config.IMG_SIZE)\n",
    "    h_count = math.ceil(test_img[0].shape[0] / Config.IMG_SIZE)\n",
    "\n",
    "    plt.imshow(test_img[0])\n",
    "    plt.show()\n",
    "\n",
    "    tile_arry = []\n",
    "    stack_pred = np.vstack(test_preds).reshape(-1, Config.IMG_SIZE, Config.IMG_SIZE)\n",
    "    for h_i in range(h_count):\n",
    "        tile_arry.append(stack_pred[h_i * w_count : (h_i + 1) * w_count])\n",
    "\n",
    "    plt.imshow(test_mask)\n",
    "    plt.show()\n",
    "\n",
    "    pred_tile_img = concat_tile(tile_arry)\n",
    "\n",
    "    plt.imshow(pred_tile_img)\n",
    "    plt.show()\n",
    "\n",
    "    pred_tile_img = np.where(\n",
    "        test_mask > 1,\n",
    "        pred_tile_img[\n",
    "            : test_img[0].shape[0],\n",
    "            : test_img[0].shape[1],\n",
    "        ],\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    return pred_tile_img"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.025087,
     "end_time": "2023-03-19T04:55:06.036667",
     "exception": false,
     "start_time": "2023-03-19T04:55:06.011580",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "papermill": {
     "duration": 0.006965,
     "end_time": "2023-03-19T04:55:06.050620",
     "exception": false,
     "start_time": "2023-03-19T04:55:06.043655",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test data inference"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.00687,
     "end_time": "2023-03-19T04:55:06.064541",
     "exception": false,
     "start_time": "2023-03-19T04:55:06.057671",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_root_dir = DATA_DIR / \"test/*\"\n",
    "\n",
    "pred_list = []\n",
    "for f in glob.glob(str(test_root_dir)):\n",
    "    print(f)\n",
    "    pred_tile_img = predict(Path(f))\n",
    "\n",
    "    # plt.imshow(pred_tile_img)\n",
    "    # plt.show()\n",
    "\n",
    "    # if is_train:\n",
    "        # plt.figure(figsize=(20, 20))\n",
    "    # plt.imshow(np.where(pred_tile_img > 0.15, 1, 0))\n",
    "    # plt.show()\n",
    "\n",
    "    starts_ix, lengths = rle(pred_tile_img, thr=0.4)\n",
    "    # inklabels_rle = \" \".join(map(str, sum(zip(starts_ix, lengths), ())))\n",
    "    # inklabels_rle\n",
    "\n",
    "    predicted_arr = np.stack([starts_ix, lengths]).T.flatten()\n",
    "    np.savetxt(str(OUTPUT_DIR / \"submission.csv\"), predicted_arr.reshape(1, -1), delimiter=\" \", fmt=\"%d\")"
   ],
   "metadata": {
    "papermill": {
     "duration": 2635.51486,
     "end_time": "2023-03-19T05:39:01.586647",
     "exception": false,
     "start_time": "2023-03-19T04:55:06.071787",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "papermill": {
     "duration": 0.040576,
     "end_time": "2023-03-19T05:39:01.670436",
     "exception": false,
     "start_time": "2023-03-19T05:39:01.629860",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pd.DataFrame(pred_list).to_csv(\"submission.csv\", index=False)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.174332,
     "end_time": "2023-03-19T05:39:01.884880",
     "exception": false,
     "start_time": "2023-03-19T05:39:01.710548",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "papermill": {
     "duration": 0.03993,
     "end_time": "2023-03-19T05:39:01.965774",
     "exception": false,
     "start_time": "2023-03-19T05:39:01.925844",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
