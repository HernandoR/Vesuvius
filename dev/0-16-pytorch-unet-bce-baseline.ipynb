{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119db101",
   "metadata": {
    "papermill": {
     "duration": 0.005458,
     "end_time": "2023-03-20T00:04:45.987053",
     "exception": false,
     "start_time": "2023-03-20T00:04:45.981595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this Notebook, we run a baseline with\n",
    "- Raw Unet Structure\n",
    "- BCELoss\n",
    "with full training - validation - submission code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c861e",
   "metadata": {
    "papermill": {
     "duration": 0.003918,
     "end_time": "2023-03-20T00:04:45.995381",
     "exception": false,
     "start_time": "2023-03-20T00:04:45.991463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ff3a64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:04:46.006264Z",
     "iopub.status.busy": "2023-03-20T00:04:46.005423Z",
     "iopub.status.idle": "2023-03-20T00:04:48.293319Z",
     "shell.execute_reply": "2023-03-20T00:04:48.292315Z"
    },
    "papermill": {
     "duration": 2.29655,
     "end_time": "2023-03-20T00:04:48.296076",
     "exception": false,
     "start_time": "2023-03-20T00:04:45.999526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ================= Unet ========================\n",
    "# Ref: https://www.kaggle.com/code/balraj98/unet-for-building-segmentation-pytorch\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "        self.down_sample = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_out = self.double_conv(x)\n",
    "        down_out = self.down_sample(skip_out)\n",
    "        return (down_out, skip_out)\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, up_sample_mode):\n",
    "        super(UpBlock, self).__init__()\n",
    "        if up_sample_mode == 'conv_transpose':\n",
    "            self.up_sample = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)\n",
    "        elif up_sample_mode == 'bilinear':\n",
    "            self.up_sample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported `up_sample_mode` (can take one of `conv_transpose` or `bilinear`)\")\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, down_input, skip_input):\n",
    "        x = self.up_sample(down_input)\n",
    "        x = torch.cat([x, skip_input], dim=1)\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch, out_classes=1, up_sample_mode='conv_transpose'):\n",
    "        super(UNet, self).__init__()\n",
    "        self.up_sample_mode = up_sample_mode\n",
    "        # Downsampling Path\n",
    "        self.down_conv1 = DownBlock(in_ch, 64)\n",
    "        self.down_conv2 = DownBlock(64, 128)\n",
    "        self.down_conv3 = DownBlock(128, 256)\n",
    "        self.down_conv4 = DownBlock(256, 512)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.double_conv = DoubleConv(512, 1024)\n",
    "        # Upsampling Path\n",
    "        self.up_conv4 = UpBlock(512 + 1024, 512, self.up_sample_mode)\n",
    "        self.up_conv3 = UpBlock(256 + 512, 256, self.up_sample_mode)\n",
    "        self.up_conv2 = UpBlock(128 + 256, 128, self.up_sample_mode)\n",
    "        self.up_conv1 = UpBlock(128 + 64, 64, self.up_sample_mode)\n",
    "\n",
    "        # Final Convolution\n",
    "        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip1_out = self.down_conv1(x)\n",
    "        x, skip2_out = self.down_conv2(x)\n",
    "        x, skip3_out = self.down_conv3(x)\n",
    "        x, skip4_out = self.down_conv4(x)\n",
    "        x = self.double_conv(x)\n",
    "        x = self.up_conv4(x, skip4_out)\n",
    "        x = self.up_conv3(x, skip3_out)\n",
    "        x = self.up_conv2(x, skip2_out)\n",
    "        x = self.up_conv1(x, skip1_out)\n",
    "        x = self.conv_last(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfa28e2",
   "metadata": {
    "papermill": {
     "duration": 0.004101,
     "end_time": "2023-03-20T00:04:48.304606",
     "exception": false,
     "start_time": "2023-03-20T00:04:48.300505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Dataset\n",
    "Here the RandomPatchLocDataset will draw random patch from the volume.\n",
    "\n",
    "**Full visualize** can ref: https://www.kaggle.com/code/fchollet/keras-starter-kit-unet-train-on-full-dataset\n",
    "\n",
    "On how the patch is draw / how the volume is create by concat / Where the validation set is\n",
    "\n",
    "The notebook is the same setting with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "715e5504",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-20T00:04:48.314330Z",
     "iopub.status.busy": "2023-03-20T00:04:48.313909Z",
     "iopub.status.idle": "2023-03-20T00:04:48.875927Z",
     "shell.execute_reply": "2023-03-20T00:04:48.874829Z"
    },
    "papermill": {
     "duration": 0.569726,
     "end_time": "2023-03-20T00:04:48.878508",
     "exception": false,
     "start_time": "2023-03-20T00:04:48.308782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "# ================== random patch dataset ==============================\n",
    "is_local = (_dh != [\"/kaggle/working\"])\n",
    "\n",
    "class RandomOpt():\n",
    "    def __init__(self):\n",
    "        self.SHARED_HEIGHT = 4096  # Height to resize all papyrii\n",
    "        self.BUFFER = 64  # Half-size of papyrus patches we'll use as model inputs\n",
    "        self.Z_DIM = 16  # Number of slices in the z direction. Max value is 64 - Z_START\n",
    "        self.Z_START = 25  # Offset of slices in the z direction\n",
    "        if is_local:\n",
    "            self.DATA_DIR = \"../data/raw/\"\n",
    "        else:\n",
    "            self.DATA_DIR = \"/kaggle/input/vesuvius-challenge-ink-detection\"\n",
    "\n",
    "def resize(img, SHARED_HEIGHT=RandomOpt().SHARED_HEIGHT):\n",
    "    current_width, current_height = img.size\n",
    "    aspect_ratio = current_width / current_height\n",
    "    new_width = int(SHARED_HEIGHT * aspect_ratio)\n",
    "    new_size = (new_width, SHARED_HEIGHT)\n",
    "    img = img.resize(new_size)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_mask(split, index, DATA_DIR=RandomOpt().DATA_DIR):\n",
    "    img = Image.open(f\"{DATA_DIR}/{split}/{index}/mask.png\").convert('1')\n",
    "    img = resize(img)\n",
    "    return torch.from_numpy(np.array(img))\n",
    "\n",
    "def load_labels(split, index, DATA_DIR=RandomOpt().DATA_DIR):\n",
    "    img = Image.open(f\"{DATA_DIR}/{split}/{index}/inklabels.png\")\n",
    "    img = resize(img)\n",
    "    return torch.from_numpy(np.array(img)).gt(0).float()\n",
    "\n",
    "def load_volume(split, index, DATA_DIR=RandomOpt().DATA_DIR, Z_START=RandomOpt().Z_START, Z_DIM=RandomOpt().Z_DIM):\n",
    "    # Load the 3d x-ray scan, one slice at a time\n",
    "    z_slices_fnames = sorted(glob.glob(f\"{DATA_DIR}/{split}/{index}/surface_volume/*.tif\"))[Z_START:Z_START + Z_DIM]\n",
    "    z_slices = []\n",
    "    for z, filename in  tqdm(enumerate(z_slices_fnames)):\n",
    "        img = Image.open(filename)\n",
    "        img = resize(img)\n",
    "        z_slice = np.array(img, dtype=\"float32\")\n",
    "        z_slices.append(torch.from_numpy(z_slice))\n",
    "    return torch.stack(z_slices, dim=0)\n",
    "\n",
    "# Random choice of patches for training\n",
    "def sample_random_location(shape, BUFFER=RandomOpt().BUFFER):\n",
    "    a=BUFFER\n",
    "    random_train_x = (shape[0] - BUFFER - 1 - a)*torch.rand(1)+a\n",
    "    random_train_y = (shape[1] - BUFFER - 1 - a)*torch.rand(1)+a\n",
    "    random_train_location = torch.stack([random_train_x, random_train_y])\n",
    "    return random_train_location\n",
    "\n",
    "def is_in_masked_zone(location, mask):\n",
    "    return mask[location[0].long(), location[1].long()]\n",
    "\n",
    "def is_in_val_zone(location, val_location, val_zone_size, BUFFER=RandomOpt().BUFFER):\n",
    "    x = location[0]\n",
    "    y = location[1]\n",
    "    x_match = val_location[0] - BUFFER <= x <= val_location[0] + val_zone_size[0] + BUFFER\n",
    "    y_match = val_location[1] - BUFFER <= y <= val_location[1] + val_zone_size[1] + BUFFER\n",
    "    return x_match and y_match\n",
    "\n",
    "class RandomPatchLocDataset(data.Dataset):\n",
    "    def __init__(self, mask, val_location, val_zone_size):\n",
    "        self.mask = mask\n",
    "        self.val_location = val_location\n",
    "        self.val_zone_size = val_zone_size\n",
    "        self.sample_random_location_train = lambda x: sample_random_location(mask.shape)\n",
    "        self.is_in_mask_train = lambda x: is_in_masked_zone(x, mask)\n",
    "\n",
    "    def is_proper_train_location(self, location):\n",
    "        return not is_in_val_zone(location, self.val_location, self.val_zone_size) and self.is_in_mask_train(location)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1280\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate a random patch\n",
    "        # Ignore the index\n",
    "        loc = self.sample_random_location_train(0)\n",
    "        while not self.is_proper_train_location(loc):\n",
    "            loc = self.sample_random_location_train(0)\n",
    "        return loc.int().squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443a046d",
   "metadata": {
    "papermill": {
     "duration": 0.004482,
     "end_time": "2023-03-20T00:04:48.889035",
     "exception": false,
     "start_time": "2023-03-20T00:04:48.884553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define training and validation model\n",
    "The full code with the model with Unet and random patch.\n",
    "\n",
    "We will save the best model on validation.\n",
    "\n",
    "NOTE: You can also download the model in OUTPUT and run test Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3b9fada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:04:48.899124Z",
     "iopub.status.busy": "2023-03-20T00:04:48.898820Z",
     "iopub.status.idle": "2023-03-20T00:04:48.927160Z",
     "shell.execute_reply": "2023-03-20T00:04:48.926096Z"
    },
    "papermill": {
     "duration": 0.036127,
     "end_time": "2023-03-20T00:04:48.929309",
     "exception": false,
     "start_time": "2023-03-20T00:04:48.893182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============= Model ==============\n",
    "class ModelOpt:\n",
    "    def __init__(self):\n",
    "        # self.GPU_ID = '0'  \n",
    "        self.Z_DIM = RandomOpt().Z_DIM\n",
    "        self.BUFFER = RandomOpt().BUFFER\n",
    "        self.SEED = 0\n",
    "        self.BATCH_SIZE = 64\n",
    "        self.LEARNING_RATE =1e-4\n",
    "        self.TRAINING_EPOCH = 20\n",
    "        self.LOG_DIR = '/kaggle/working'\n",
    "        self.LOAD_VOLUME = [1, 2, 3]\n",
    "        # Val\n",
    "        self.VAL_LOC = (1300, 1000)\n",
    "        self.VAL_SIZE = (300, 7000)\n",
    "\n",
    "class RandomPatchModel():\n",
    "    def __init__(self, opt = ModelOpt()):\n",
    "        self.opt = opt\n",
    "        self._setup_all()\n",
    "        self.volume_list = [load_volume('train', i) for i in opt.LOAD_VOLUME]\n",
    "        # Here volume: [Z_DIM, SHARED_HEIGHT, W_V1 + W_V2 + ...]\n",
    "        self.volume = torch.cat(self.volume_list, dim=2)\n",
    "        # Same for mask and label\n",
    "        self.mask_list = [load_mask('train', i) for i in opt.LOAD_VOLUME]\n",
    "        self.labels_list = [load_labels('train', i) for i in opt.LOAD_VOLUME]\n",
    "        # [SHARED_HEIGHT, W_V1 + W_V2 + ...]\n",
    "        self.labels = torch.cat(self.labels_list, dim=1)\n",
    "        self.mask = torch.cat(self.mask_list, dim=1)\n",
    "\n",
    "        self.net = UNet(in_ch=opt.Z_DIM).to(self.device)\n",
    "\n",
    "        # Dataset\n",
    "        self.loc_datast = RandomPatchLocDataset(self.mask, val_location=opt.VAL_LOC, val_zone_size=opt.VAL_SIZE)\n",
    "        self.loc_loader = data.DataLoader(self.loc_datast, batch_size=opt.BATCH_SIZE)\n",
    "        # Val\n",
    "        self.val_loc = []\n",
    "        for x in range(opt.VAL_LOC[0], opt.VAL_LOC[0] + opt.VAL_SIZE[0], opt.BUFFER):\n",
    "            for y in range(opt.VAL_LOC[1], opt.VAL_LOC[1] + opt.VAL_SIZE[1], opt.BUFFER):\n",
    "                if is_in_masked_zone([torch.tensor(x),torch.tensor(y)], self.mask):\n",
    "                    self.val_loc.append([[x, y]])\n",
    "        print(f\"======> Num Patches Val: {len(self.val_loc)}\")\n",
    "\n",
    "\n",
    "    def _setup_all(self):\n",
    "        # random seed\n",
    "        np.random.seed(self.opt.SEED)\n",
    "        torch.manual_seed(self.opt.SEED)\n",
    "        torch.cuda.manual_seed_all(self.opt.SEED)\n",
    "        # torch\n",
    "        # os.environ['CUDA_VISIBLE_DEVICES'] = self.opt.GPU_ID\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # Log\n",
    "        self.log_dir = self.opt.LOG_DIR\n",
    "        self.ckpt = os.path.join(self.log_dir)\n",
    "\n",
    "    def get_subvolume(self, batch_loc, volume, labels):\n",
    "        # batch_loc : [batch_size, 2]\n",
    "        subvolume = []\n",
    "        label = []\n",
    "        for l in batch_loc:\n",
    "            x = l[0]\n",
    "            y = l[1]\n",
    "            sv = volume[:, x - self.opt.BUFFER:x + self.opt.BUFFER, y - self.opt.BUFFER:y + self.opt.BUFFER]\n",
    "            sv = sv / 65535.\n",
    "            subvolume.append(sv)\n",
    "            if labels is not None:\n",
    "                lb = labels[x - self.opt.BUFFER:x + self.opt.BUFFER, y - self.opt.BUFFER:y + self.opt.BUFFER]\n",
    "                lb = lb.unsqueeze(0)\n",
    "                label.append(lb)\n",
    "        # [batch, Z_DIM, BUFFER, BUFFER]\n",
    "        subvolume = torch.stack(subvolume)\n",
    "        # [batch, 1, BUFFER, BUFFER]\n",
    "        if labels is not None:\n",
    "            label = torch.stack(label)\n",
    "        return subvolume, label\n",
    "\n",
    "    def augment_train_data(self, subvolume, label):\n",
    "        # Add Data augmentation here\n",
    "        return subvolume, label\n",
    "\n",
    "    def train_loop(self):\n",
    "        print(\"=====> Begin training\")\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.opt.LEARNING_RATE)\n",
    "        self.net.train()\n",
    "\n",
    "        best_val_loss = 100\n",
    "        best_val_acc = 0\n",
    "        meter = AverageMeter()\n",
    "        for epoch in range(self.opt.TRAINING_EPOCH):\n",
    "            bar = tqdm(enumerate(self.loc_loader), total=len(self.loc_datast) / self.opt.BATCH_SIZE)\n",
    "            bar.set_description_str(f\"Epoch: {epoch}\")\n",
    "            for i, loc in bar:\n",
    "                subvolume, label = self.get_subvolume(loc, self.volume, self.labels)\n",
    "                loss = self._train_step(subvolume, label)\n",
    "                meter.update(loss)\n",
    "                bar.set_postfix_str(f\"Avg loss: {np.round(meter.get_value(),3)}\")\n",
    "\n",
    "            val_loss, val_acc = self.validataion_loop()\n",
    "            print(f\"======> Val Loss:{np.round(val_loss,3)} | Val Acc:{np.round(val_acc,3)} \")\n",
    "            if val_loss < best_val_loss and val_acc > best_val_acc:\n",
    "                torch.save(self.net.state_dict(), os.path.join(self.ckpt, \"best.pt\"))\n",
    "                print(\"======> Save best val model\")\n",
    "\n",
    "                best_val_loss = val_loss\n",
    "                best_val_acc = val_acc\n",
    "\n",
    "\n",
    "\n",
    "    def _train_step(self, subvolume, label):\n",
    "        self.optimizer.zero_grad()\n",
    "        # inputs: subvolume: [batch, Z_DIM, BUFFER, BUFFER]\n",
    "        #         label: [batch, 1, BUFFER, BUFFER]\n",
    "        outputs = self.net(subvolume.to(self.device))\n",
    "        loss = self.criterion(outputs, label.to(self.device))\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss\n",
    "\n",
    "    def validataion_loop(self):\n",
    "        meter_loss = AverageMeter()\n",
    "        meter_acc = AverageMeter()\n",
    "        self.net.eval()\n",
    "        for loc in self.val_loc:\n",
    "            subvolume, label = self.get_subvolume(loc, self.volume, self.labels)\n",
    "            outputs = self.net(subvolume.to(self.device))\n",
    "            loss = self.criterion(outputs, label.to(self.device))\n",
    "            meter_loss.update(loss)\n",
    "            pred = torch.sigmoid(outputs) > 0.5\n",
    "            meter_acc.update(\n",
    "                (pred == label.to(self.device)).sum(),\n",
    "                int(torch.prod(torch.tensor(label.shape)))\n",
    "            )\n",
    "        self.net.train()\n",
    "        return meter_loss.get_value(), meter_acc.get_value()\n",
    "\n",
    "    def load_best_ckpt(self):\n",
    "        self.net.load_state_dict(torch.load(os.path.join(self.ckpt, \"best.pt\")))\n",
    "\n",
    "\n",
    "# For the metric\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.sum = 0\n",
    "        self.n = 0\n",
    "\n",
    "    def update(self, x, n=1):\n",
    "        self.sum += float(x)\n",
    "        self.n += n\n",
    "\n",
    "    def reset(self):\n",
    "        self.sum = 0\n",
    "        self.n = 0\n",
    "\n",
    "    def get_value(self):\n",
    "        if self.n:\n",
    "            return self.sum / self.n\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d536bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:04:48.938901Z",
     "iopub.status.busy": "2023-03-20T00:04:48.938613Z",
     "iopub.status.idle": "2023-03-20T00:07:48.407885Z",
     "shell.execute_reply": "2023-03-20T00:07:48.405572Z"
    },
    "papermill": {
     "duration": 179.477218,
     "end_time": "2023-03-20T00:07:48.410752",
     "exception": false,
     "start_time": "2023-03-20T00:04:48.933534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:09,  1.76it/s]\n",
      "0it [00:00, ?it/s]c:\\Users\\lzhen\\miniconda3\\envs\\Vesuvius\\lib\\site-packages\\PIL\\Image.py:3167: DecompressionBombWarning: Image size (140973980 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "16it [00:09,  1.60it/s]\n",
      "16it [00:04,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> Num Patches Val: 347\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = RandomPatchModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82eff542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:07:48.428291Z",
     "iopub.status.busy": "2023-03-20T00:07:48.426806Z",
     "iopub.status.idle": "2023-03-20T00:12:49.032110Z",
     "shell.execute_reply": "2023-03-20T00:12:49.030448Z"
    },
    "papermill": {
     "duration": 300.616708,
     "end_time": "2023-03-20T00:12:49.035172",
     "exception": false,
     "start_time": "2023-03-20T00:07:48.418464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Begin training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 20/20.0 [00:26<00:00,  1.31s/it, Avg loss: 0.587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> Val Loss:0.594 | Val Acc:0.814 \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory /kaggle does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[39m# Training\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m model\u001B[39m.\u001B[39;49mtrain_loop()\n",
      "Cell \u001B[1;32mIn[10], line 105\u001B[0m, in \u001B[0;36mRandomPatchModel.train_loop\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[39mprint\u001B[39m(\u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39m======> Val Loss:\u001B[39m\u001B[39m{\u001B[39;00mnp\u001B[39m.\u001B[39mround(val_loss,\u001B[39m3\u001B[39m)\u001B[39m}\u001B[39;00m\u001B[39m | Val Acc:\u001B[39m\u001B[39m{\u001B[39;00mnp\u001B[39m.\u001B[39mround(val_acc,\u001B[39m3\u001B[39m)\u001B[39m}\u001B[39;00m\u001B[39m \u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[0;32m    104\u001B[0m \u001B[39mif\u001B[39;00m val_loss \u001B[39m<\u001B[39m best_val_loss \u001B[39mand\u001B[39;00m val_acc \u001B[39m>\u001B[39m best_val_acc:\n\u001B[1;32m--> 105\u001B[0m     torch\u001B[39m.\u001B[39;49msave(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mnet\u001B[39m.\u001B[39;49mstate_dict(), os\u001B[39m.\u001B[39;49mpath\u001B[39m.\u001B[39;49mjoin(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mckpt, \u001B[39m\"\u001B[39;49m\u001B[39mbest.pt\u001B[39;49m\u001B[39m\"\u001B[39;49m))\n\u001B[0;32m    106\u001B[0m     \u001B[39mprint\u001B[39m(\u001B[39m\"\u001B[39m\u001B[39m======> Save best val model\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[0;32m    108\u001B[0m     best_val_loss \u001B[39m=\u001B[39m val_loss\n",
      "File \u001B[1;32mc:\\Users\\lzhen\\miniconda3\\envs\\Vesuvius\\lib\\site-packages\\torch\\serialization.py:440\u001B[0m, in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001B[0m\n\u001B[0;32m    437\u001B[0m _check_save_filelike(f)\n\u001B[0;32m    439\u001B[0m \u001B[39mif\u001B[39;00m _use_new_zipfile_serialization:\n\u001B[1;32m--> 440\u001B[0m     \u001B[39mwith\u001B[39;00m _open_zipfile_writer(f) \u001B[39mas\u001B[39;00m opened_zipfile:\n\u001B[0;32m    441\u001B[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001B[0;32m    442\u001B[0m         \u001B[39mreturn\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\lzhen\\miniconda3\\envs\\Vesuvius\\lib\\site-packages\\torch\\serialization.py:315\u001B[0m, in \u001B[0;36m_open_zipfile_writer\u001B[1;34m(name_or_buffer)\u001B[0m\n\u001B[0;32m    313\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m    314\u001B[0m     container \u001B[39m=\u001B[39m _open_zipfile_writer_buffer\n\u001B[1;32m--> 315\u001B[0m \u001B[39mreturn\u001B[39;00m container(name_or_buffer)\n",
      "File \u001B[1;32mc:\\Users\\lzhen\\miniconda3\\envs\\Vesuvius\\lib\\site-packages\\torch\\serialization.py:288\u001B[0m, in \u001B[0;36m_open_zipfile_writer_file.__init__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m__init__\u001B[39m(\u001B[39mself\u001B[39m, name) \u001B[39m-\u001B[39m\u001B[39m>\u001B[39m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m--> 288\u001B[0m     \u001B[39msuper\u001B[39m()\u001B[39m.\u001B[39m\u001B[39m__init__\u001B[39m(torch\u001B[39m.\u001B[39;49m_C\u001B[39m.\u001B[39;49mPyTorchFileWriter(\u001B[39mstr\u001B[39;49m(name)))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Parent directory /kaggle does not exist."
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.train_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2be1f0",
   "metadata": {
    "papermill": {
     "duration": 0.051613,
     "end_time": "2023-03-20T00:12:49.139593",
     "exception": false,
     "start_time": "2023-03-20T00:12:49.087980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5b72b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:12:49.245472Z",
     "iopub.status.busy": "2023-03-20T00:12:49.244462Z",
     "iopub.status.idle": "2023-03-20T00:12:51.715624Z",
     "shell.execute_reply": "2023-03-20T00:12:51.714513Z"
    },
    "papermill": {
     "duration": 2.529885,
     "end_time": "2023-03-20T00:12:51.721467",
     "exception": false,
     "start_time": "2023-03-20T00:12:49.191582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the best model\n",
    "model.load_best_ckpt()\n",
    "model.criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "loss, acc = model.validataion_loop()\n",
    "model.net.eval()\n",
    "print(f\"Val loss: {np.round(loss,3)} | Val acc: {np.round(acc, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84cb7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:12:51.907963Z",
     "iopub.status.busy": "2023-03-20T00:12:51.907444Z",
     "iopub.status.idle": "2023-03-20T00:12:51.922795Z",
     "shell.execute_reply": "2023-03-20T00:12:51.921728Z"
    },
    "papermill": {
     "duration": 0.09676,
     "end_time": "2023-03-20T00:12:51.925147",
     "exception": false,
     "start_time": "2023-03-20T00:12:51.828387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def compute_predictions_map(split, index):\n",
    "    print(f\"======> Load data for {split}/{index}\")\n",
    "    test_volume = load_volume(split=split, index=index)\n",
    "    test_mask = load_mask(split=split, index=index)\n",
    "    print(f\"======> Volume shape: {test_volume.shape}\")\n",
    "    test_locations = []\n",
    "    BUFFER = model.opt.BUFFER\n",
    "    stride = BUFFER // 2\n",
    "\n",
    "    for x in range(BUFFER, test_volume.shape[1] - BUFFER, stride):\n",
    "        for y in range(BUFFER, test_volume.shape[2] - BUFFER, stride):\n",
    "            if is_in_masked_zone([torch.tensor(x),torch.tensor(y)], test_mask):\n",
    "                test_locations.append((x, y))\n",
    "    print(f\"======> {len(test_locations)} test locations (after filtering by mask)\")\n",
    "\n",
    "    predictions_map = torch.zeros((1, 1, test_volume.shape[1], test_volume.shape[2]))\n",
    "    predictions_map_counts = torch.zeros((1, 1, test_volume.shape[1], test_volume.shape[2]))\n",
    "    print(f\"======> Compute predictions\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bar = tqdm(test_locations)\n",
    "        for loc in bar:\n",
    "            subvolume, label = model.get_subvolume([loc], test_volume, None)\n",
    "            outputs = model.net(subvolume.to(model.device))\n",
    "            pred = torch.sigmoid(outputs)\n",
    "            # print(loc, (pred > 0.5).sum())\n",
    "            # Here a single location may be with multiple result\n",
    "            predictions_map[:, :, loc[0] - BUFFER : loc[0] + BUFFER, loc[1] - BUFFER : loc[1] + BUFFER] += pred.cpu()\n",
    "            predictions_map_counts[:, :, loc[0] - BUFFER : loc[0] + BUFFER, loc[1] - BUFFER : loc[1] + BUFFER] += 1\n",
    "\n",
    "    # print(predictions_map_b[:,:, 2500, 1000])\n",
    "    # print(predictions_map_counts[:,:, 2500, 1000])\n",
    "    predictions_map /= (predictions_map_counts + 1e-7)\n",
    "    return predictions_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd0224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:12:52.081035Z",
     "iopub.status.busy": "2023-03-20T00:12:52.080543Z",
     "iopub.status.idle": "2023-03-20T00:17:02.654010Z",
     "shell.execute_reply": "2023-03-20T00:17:02.652964Z"
    },
    "papermill": {
     "duration": 250.653505,
     "end_time": "2023-03-20T00:17:02.656610",
     "exception": false,
     "start_time": "2023-03-20T00:12:52.003105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_map_a = compute_predictions_map(split=\"test\", index=\"a\")\n",
    "predictions_map_b = compute_predictions_map(split=\"test\", index=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b6a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:17:02.981155Z",
     "iopub.status.busy": "2023-03-20T00:17:02.980803Z",
     "iopub.status.idle": "2023-03-20T00:17:05.329984Z",
     "shell.execute_reply": "2023-03-20T00:17:05.328440Z"
    },
    "papermill": {
     "duration": 2.514543,
     "end_time": "2023-03-20T00:17:05.333013",
     "exception": false,
     "start_time": "2023-03-20T00:17:02.818470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Threshold is very important !!!!!\n",
    "plt.imshow(predictions_map_a.squeeze() > 0.10, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6ef71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:17:05.667542Z",
     "iopub.status.busy": "2023-03-20T00:17:05.666979Z",
     "iopub.status.idle": "2023-03-20T00:17:07.396220Z",
     "shell.execute_reply": "2023-03-20T00:17:07.395301Z"
    },
    "papermill": {
     "duration": 1.902281,
     "end_time": "2023-03-20T00:17:07.399578",
     "exception": false,
     "start_time": "2023-03-20T00:17:05.497297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(predictions_map_b.squeeze() > 0.10, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ec03b",
   "metadata": {
    "papermill": {
     "duration": 0.163725,
     "end_time": "2023-03-20T00:17:07.731732",
     "exception": false,
     "start_time": "2023-03-20T00:17:07.568007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission\n",
    "\n",
    "Rescale the pred to the raw size and create 'submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f4f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:17:08.109701Z",
     "iopub.status.busy": "2023-03-20T00:17:08.109325Z",
     "iopub.status.idle": "2023-03-20T00:17:10.783981Z",
     "shell.execute_reply": "2023-03-20T00:17:10.782875Z"
    },
    "papermill": {
     "duration": 2.84525,
     "end_time": "2023-03-20T00:17:10.786847",
     "exception": false,
     "start_time": "2023-03-20T00:17:07.941597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize as resize_ski\n",
    "import PIL.Image as Image\n",
    "\n",
    "DATA_DIR = \"/kaggle/input/vesuvius-challenge-ink-detection\"\n",
    "original_size_a = Image.open(DATA_DIR + \"/test/a/mask.png\").size\n",
    "original_size_b = Image.open(DATA_DIR + \"/test/b/mask.png\").size\n",
    "predictions_map_a = resize_ski(predictions_map_a.squeeze(), original_size_a).squeeze()\n",
    "predictions_map_b = resize_ski(predictions_map_b.squeeze(), original_size_b).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a09b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:17:11.122881Z",
     "iopub.status.busy": "2023-03-20T00:17:11.122505Z",
     "iopub.status.idle": "2023-03-20T00:23:33.728242Z",
     "shell.execute_reply": "2023-03-20T00:23:33.727131Z"
    },
    "papermill": {
     "duration": 382.776752,
     "end_time": "2023-03-20T00:23:33.730970",
     "exception": false,
     "start_time": "2023-03-20T00:17:10.954218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle(predictions_map, threshold):\n",
    "    flat_img = predictions_map.flatten()\n",
    "    flat_img = np.where(flat_img > threshold, 1, 0).astype(np.uint8)\n",
    "\n",
    "    starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n",
    "    ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n",
    "    starts_ix = np.where(starts)[0] + 2\n",
    "    ends_ix = np.where(ends)[0] + 2\n",
    "    lengths = ends_ix - starts_ix\n",
    "    return \" \".join(map(str, sum(zip(starts_ix, lengths), ())))\n",
    "\n",
    "threshold_a = 0.10\n",
    "threshold_b = 0.10\n",
    "\n",
    "rle_a = rle(predictions_map_a, threshold=threshold_a)\n",
    "rle_b = rle(predictions_map_b, threshold=threshold_b)\n",
    "print(\"Id,Predicted\\na,\" + rle_a + \"\\nb,\" + rle_b, file=open('/kaggle/working/submission.csv', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb84b8b",
   "metadata": {
    "papermill": {
     "duration": 0.166574,
     "end_time": "2023-03-20T00:23:34.063872",
     "exception": false,
     "start_time": "2023-03-20T00:23:33.897298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Next step\n",
    "You can\n",
    "- Try different architecture in Unet:\n",
    "    - Other size\n",
    "    - Attention Block\n",
    "- Tune the hyperparameter\n",
    "    - Z_DIM ...\n",
    "- Use more suitable segmentation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1199d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T00:23:34.400783Z",
     "iopub.status.busy": "2023-03-20T00:23:34.400421Z",
     "iopub.status.idle": "2023-03-20T00:23:34.404837Z",
     "shell.execute_reply": "2023-03-20T00:23:34.403722Z"
    },
    "papermill": {
     "duration": 0.176578,
     "end_time": "2023-03-20T00:23:34.407199",
     "exception": false,
     "start_time": "2023-03-20T00:23:34.230621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1140.442464,
   "end_time": "2023-03-20T00:23:37.300328",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-20T00:04:36.857864",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
